{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION-1\n",
    "Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_loc=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys('banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"9f0aedd6-ee62-41f7-9990-0c33e986945c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"c92c50e4-a2c4-444c-b96a-e2d36cca43e3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"5cd1e25b-a8ca-4ab0-84ce-4f244a2fc240\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"c9c5cd3a-5eae-499b-b2a5-9309daa59d29\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"5a39be46-fa14-4ed2-b6a9-7cc5e82306f4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"75919524-ace4-497e-9c81-6ed76d477821\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"951d2187-2ce0-4e47-9100-e1b7f855d216\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"f7e06216-54ed-449c-8859-8bbe40c6fb7f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"5fe37cce-4885-4b6d-a6ab-98fe3f89dbd8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"77353ee7-8431-4997-9113-cf1ae8133f03\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"4653f351-a80c-4fa5-9897-482d00f73007\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"ffa3e6bf-a7fd-4263-9a43-a6958f3a6f58\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"054154fa-e28c-4d87-b707-0a79ad3989ab\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"af595e97-f132-4cdb-9814-84b1fa143794\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"459215f1-2e80-4422-ba46-d5031092284f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"a3ea18b9-d7bb-4cbc-85b4-aba9634cd591\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"7edfb465-53dc-45f7-a4d7-225f5e5cca28\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"ed7f4971-9773-4ab0-b7f0-25f42e881d91\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"f34ee260-67d3-422c-ab37-e55407989402\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"e8fdf980-b043-420c-93a6-d96d878bff6c\")>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title=driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/a')\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business Data Analyst - Google Data Studio & SQL',\n",
       " 'Executive Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst - I/II',\n",
       " 'Data Analyst',\n",
       " 'Hiring For the role - DATA Analyst (Flipkart)',\n",
       " 'Hiring For the role - DATA Analyst (Flipkart)',\n",
       " 'Business Data Analyst - MIS & Reporting',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles=[]\n",
    "for i in job_title:\n",
    "    job_titles.append(i.text)\n",
    "    \n",
    "job_titles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"05bfc38f-e722-465d-b0c4-d750a076f1e9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"09f63e0f-ed05-4470-886e-10a35f55125a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"fa5cfb66-9204-43c9-9c90-c0c2050892ed\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"5ecdeb9f-5b04-49a0-b4d7-36ba484fb90f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"8fd1f6a2-9461-4839-8aa0-a0bc614fb4b3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"83acf7d3-37b9-4fdd-b86d-17e21225e7c6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"8cab8b75-e429-4ab8-983f-7ee80c6cf020\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"f4d45b86-2451-428b-bf89-a35df5251034\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"9e13fe96-fa51-4f28-b645-94df80941cef\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"98731f6c-f0e6-4c9e-832a-9fdee6091266\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"0a2ecab6-d875-47df-a260-4a0f77417432\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"0b74bbac-a268-4b44-ba0a-acea42ac892b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"418b0097-eceb-413c-ba01-cdfbbd73ae63\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"4a0264d1-c40b-4e4a-b488-df0b9913004f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"7217bc45-fcf6-4054-881c-5a4cd38285b3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"b6c930b8-2316-4b44-8e31-e5a63289d5e6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"365d397a-c27e-4fed-8ef7-8be9c8ee6cce\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"04a848b4-8d17-428b-81db-c37aef9b7bf1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"1232c982-275e-4a19-85bf-d7873476a30c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"e5b6b00d-98c6-4438-b23e-a01eb9f14067\")>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cname=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "cname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AVE-Promagne',\n",
       " 'Gokaldas Exports Ltd',\n",
       " 'Virtusa Consulting Services Pvt Ltd',\n",
       " 'Philips India Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'INTERTRUST GROUP',\n",
       " 'Flipkart',\n",
       " 'Flipkart']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name=[]\n",
    "for i in cname:\n",
    "    company_name.append(i.text)\n",
    "company_name[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"9e71a7b5-212b-4ea0-8698-7b242fe5d532\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"7b7d83db-bb8c-4b15-8ef5-f6592738e9f1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"cdf42621-d946-4965-ae45-f2a33091511e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"4f2192d7-1ab6-4e87-8081-c9550f12f76c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"245dbe6f-b0c2-4b7d-b3f1-799e4edec690\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"e1789c3d-2096-4b3f-9158-7ce1a5e7208e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"53b127cf-f159-4344-9785-bc871b9a135b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"571d17e1-5ba7-49c6-a690-5cbab9737cda\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"ea8d880e-b124-497c-9532-080c223ce610\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"d5d3fc1f-f11d-4bc6-8b3a-abc402d906bf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"0e72e032-de91-42aa-a1c9-f7d1c95bc61f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"2d26a896-1731-45c1-b0fe-f559e6a6157a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"12c88953-b9b5-4cc4-8dd7-25ce4409cfa4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"8277c266-90b5-4c6e-920e-20cfc9cca701\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"41ec17b1-b7ea-4c1d-8bb5-f414f9f8efe3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"c08d54f3-c19c-4838-8640-a7f890914e71\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"3eba82a5-ca9d-4ee2-ad7d-97ae2a38fc75\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"4ecfef54-6bfb-4568-8ae1-d13e0d715f69\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"35365117-fcb1-4715-ac4f-7b2cb4d05b4e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"517c3c48-ac90-46cc-ab92-b6c97a68699a\")>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_loc=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span[1]')\n",
    "job_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru(Bellandur)',\n",
       " 'Bangalore/Bengaluru(Bellandur)',\n",
       " 'Mumbai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job__location=[]\n",
    "for i in job_loc:\n",
    "    job__location.append(i.text)\n",
    "job__location[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job__location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"96297182-8fe3-4a87-b73f-3b716b2e6a20\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"61160684-0e3d-4650-8d19-658edfa1f6e0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"3dd54da3-06b9-4c5b-9ef1-791c27a19514\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"e85de764-de2c-4923-90e1-178c5ff8599c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"0e736e43-734f-4ba8-9767-680b3bb484c1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"5d6c92a4-5f4d-424a-a387-fa9b9c2cf84a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"bd3f89c6-4bf9-4bbd-bde1-25aede8b4f34\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"12358b6f-4a91-4698-b5c6-adcdec8c95cb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"99b13e3a-dc85-4b22-b9d0-71174220d6be\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"d6ce36e5-262c-4dc7-bac0-bc606c63c340\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"6cc347ae-2e3f-4d7d-9675-8c6180235b06\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"13f85c04-0c50-49d4-bfe0-5a07e434b654\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"fba5b989-bdc3-4ddf-9c2c-454c9279c0f9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"e78ae2e2-5d8e-49bf-815d-74b4c8f6ef5d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"ccc97836-6714-4e80-8746-4e6092f6e41c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"bc348b4f-4068-44ea-ba00-3d633f9e2e29\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"ab53711a-6540-4888-b17a-657ff0ca8339\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"c9e544fc-8aeb-4e9e-86e9-07c3dc65ef3d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"0b6631c0-3097-49c0-9760-4797b0591394\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"65980e77c0d4f183e162c69cb78688d7\", element=\"135f1dbc-0c91-44f2-8923-23a24d170f69\")>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-8 Yrs',\n",
       " '0-3 Yrs',\n",
       " '8-12 Yrs',\n",
       " '3-6 Yrs',\n",
       " '1-4 Yrs',\n",
       " '1-6 Yrs',\n",
       " '1-6 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-3 Yrs',\n",
       " '3-8 Yrs']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience=[]\n",
    "\n",
    "for i in exp:\n",
    "    \n",
    "    experience.append(i.text)\n",
    "    \n",
    "experience[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>EXPERIENCE_REQUIRED</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Data Analyst - Google Data Studio &amp; SQL</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Executive Data Analyst</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gokaldas Exports Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...</td>\n",
       "      <td>Virtusa Consulting Services Pvt Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - I/II</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For the role - DATA Analyst (Flipkart)</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For the role - DATA Analyst (Flipkart)</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business Data Analyst - MIS &amp; Reporting</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>INTERTRUST GROUP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JOB_TITLE EXPERIENCE_REQUIRED  \\\n",
       "0  Business Data Analyst - Google Data Studio & SQL             3-8 Yrs   \n",
       "1                            Executive Data Analyst             0-3 Yrs   \n",
       "2                               Senior Data Analyst            8-12 Yrs   \n",
       "3                               Data Analyst - I/II             3-6 Yrs   \n",
       "4                                      Data Analyst             1-4 Yrs   \n",
       "5     Hiring For the role - DATA Analyst (Flipkart)             1-6 Yrs   \n",
       "6     Hiring For the role - DATA Analyst (Flipkart)             1-6 Yrs   \n",
       "7           Business Data Analyst - MIS & Reporting             3-8 Yrs   \n",
       "8                               Senior Data Analyst             2-3 Yrs   \n",
       "9                               Senior Data Analyst             3-8 Yrs   \n",
       "\n",
       "                                            LOCATION  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bengaluru/Bangalore   \n",
       "5                     Bangalore/Bengaluru(Bellandur)   \n",
       "6                     Bangalore/Bengaluru(Bellandur)   \n",
       "7                        Mumbai, Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                          COMPANY_NAME  \n",
       "0                         AVE-Promagne  \n",
       "1                 Gokaldas Exports Ltd  \n",
       "2  Virtusa Consulting Services Pvt Ltd  \n",
       "3                Philips India Limited  \n",
       "4               IBM India Pvt. Limited  \n",
       "5     Allegis Services India Pvt. Ltd.  \n",
       "6     Allegis Services India Pvt. Ltd.  \n",
       "7                     INTERTRUST GROUP  \n",
       "8                             Flipkart  \n",
       "9                             Flipkart  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "df[\"JOB_TITLE\"]=job_titles[:10]\n",
    "df[\"EXPERIENCE_REQUIRED\"]=experience[:10]\n",
    "df[\"LOCATION\"]=job__location[:10]\n",
    "df[\"COMPANY_NAME\"]=company_name[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver\")\n",
    "\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "\n",
    "\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "search_loc=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys('banglore')\n",
    "\n",
    "search_button=driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search_button.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"5c1d74be-c61e-4a00-b704-811868d3ea92\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"91bf2120-3148-49ef-a00c-dd1248847234\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"0913f490-d449-42a7-9f8a-ae1bae057a63\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"5724d99f-60e5-4aa6-b3bf-842b6d24b9e9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"f0c0080a-71c5-4d1b-ab8e-27e0fbed530c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"37344644-98ab-4b05-85ea-daff056a9ce3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"2bb6fddc-8c42-4490-acf1-82b1289259d0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"3877e70a-4aa9-4b6e-97d9-403e1ce53e70\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"db012fc8-55e2-4585-92b2-2e798403f548\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"b0b2ff93-0639-4ee6-8f55-d2560c21608b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"4fa8fa5c-56fa-4274-af38-8489d1c69c41\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"ece3fb2b-445c-45d7-a300-2758d74a871b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"50ed5f24-9d95-4450-bf6c-a3f172ab23fb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"0282ed02-d829-47b8-965d-d7cf83baad5e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"ef264fe7-9ce9-4bc3-8ab8-a6a9dc44e761\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"bae8262f-5a11-4b63-9ef4-19066d131fb3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"40f025b4-4545-42a8-a716-0c0d8079e5f4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"b178fbff-7310-4e4f-878d-0a3c01f399e9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"601ce50a-838d-4641-972c-479d5104f15d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"2cee862f99dba4c37e6091f529fcf55a\", element=\"0d01ce15-9005-47c4-97fc-6ff8e8a7fae1\")>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-lead-data-scientist-bfsi-ibm-india-pvt-limited-bengaluru-bangalore-5-to-9-years-070921901691?src=jobsearchDesk&sid=16311037411279333&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-associate-data-scientist-philips-india-limited-bangalore-bengaluru-3-to-5-years-060921501985?src=jobsearchDesk&sid=16311037411279333&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-advanced-analytics-ibm-india-pvt-limited-bengaluru-bangalore-3-to-7-years-070921901677?src=jobsearchDesk&sid=16311037411279333&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-happiest-minds-technologies-pvt-ltd-bangalore-bengaluru-5-to-10-years-070921501517?src=jobsearchDesk&sid=16311037411279333&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-python-sql-ave-promagne-hyderabad-secunderabad-chennai-bangalore-bengaluru-6-to-8-years-060921904967?src=jobsearchDesk&sid=16311037411279333&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-ibm-india-pvt-limited-bengaluru-bangalore-6-to-8-years-010921906637?src=jobsearchDesk&sid=16311037411279333&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-ibm-india-pvt-limited-bangalore-bengaluru-6-to-8-years-010921906105?src=jobsearchDesk&sid=16311037411279333&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-machine-learning-data-mining-wrackle-technologies-pvt-ltd-bangalore-bengaluru-6-to-11-years-080221900886?src=jobsearchDesk&sid=16311037411279333&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-freelance-data-scientist-project-based-shikvix-bangalore-bengaluru-3-to-8-years-060921008814?src=jobsearchDesk&sid=16311037411279333&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-neenopal-intelligent-solutions-private-limited-bangalore-bengaluru-2-to-5-years-080921006998?src=jobsearchDesk&sid=16311037411279333&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-prescience-decision-solutions-private-limited-bangalore-bengaluru-5-to-10-years-080921005624?src=jobsearchDesk&sid=16311037411279333&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-requirement-for-data-scientist-mumbai-bangalore-crisil-limited-bangalore-bengaluru-mumbai-all-areas-2-to-6-years-080921005523?src=jobsearchDesk&sid=16311037411279333&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-elpis-it-solutions-pvt-ltd-bangalore-bengaluru-3-to-8-years-070921602158?src=jobsearchDesk&sid=16311037411279333&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-elpis-it-solutions-pvt-ltd-bangalore-bengaluru-3-to-8-years-070921002157?src=jobsearchDesk&sid=16311037411279333&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-ml-sp-staffing-services-private-limited-pune-chennai-bangalore-bengaluru-10-to-15-years-100621006203?src=jobsearchDesk&sid=16311037411279333&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-oracle-india-pvt-ltd-noida-bangalore-bengaluru-5-to-9-years-010621004567?src=jobsearchDesk&sid=16311037411279333&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-ibm-india-pvt-limited-bengaluru-bangalore-2-to-4-years-010921906678?src=jobsearchDesk&sid=16311037411279333&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-cognitive-data-scientist-ibm-india-pvt-limited-bengaluru-bangalore-3-to-7-years-030921904668?src=jobsearchDesk&sid=16311037411279333&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-python-big-data-capgemini-technology-services-india-limited-hyderabad-secunderabad-chennai-bangalore-bengaluru-6-to-11-years-030921008208?src=jobsearchDesk&sid=16311037411279333&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-payments-compliance-airbnb-global-capability-center-private-limited-bangalore-bengaluru-4-to-9-years-020921903258?src=jobsearchDesk&sid=16311037411279333&xp=20&px=1']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_opening_urls=[]\n",
    "for i in url:\n",
    "    #job_title=driver.find_elements_by_xpath(\"//h1[@class='av-special-heading-tag ']\")\n",
    "    job_opening_urls.append(i.get_attribute('href'))\n",
    "job_opening_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_opening_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting job titles of the non banner type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--',\n",
       " 'Associate Data Scientist',\n",
       " '--',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'Data Scientist (Python & SQL)',\n",
       " '--',\n",
       " '--',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Freelance Data Scientist Project Based',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Requirement For Data Scientist - Mumbai & Bangalore',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist - ML',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " 'Senior Data Scientist, Payments compliance']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles=[]\n",
    "for i in job_opening_urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(10)\n",
    "    try:\n",
    "        job_title=driver.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "        job_titles.append(job_title.text)\n",
    "    except:\n",
    "        job_titles.append(\"--\")\n",
    "job_titles\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LEAD DATA SCIENTIST BFSI',\n",
       " '--',\n",
       " 'DATA SCIENTIST: ADVANCED ANALYTICS',\n",
       " '--',\n",
       " '--',\n",
       " 'SR DATA SCIENTIST',\n",
       " 'SR DATA SCIENTIST',\n",
       " '--',\n",
       " '--',\n",
       " '--']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job=[]\n",
    "for i in job_opening_urls[:10]:\n",
    "    \n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "         job_title=driver.find_element_by_xpath(\"//h1[@class='av-special-heading-tag ']\")\n",
    "    \n",
    "         job.append(job_title.text)\n",
    "    except:\n",
    "         job.append(\"--\")\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting job description for the non-banner type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--',\n",
       " 'Job descriptionnew lineUse predictive modeling to increase and optimize customer experiences, revenue generation, campaign optimization and other business outcomesnew lineWork with product management to develop data use cases and embed predictive models in workflows on resource constrained platforms and cloud enabled.new lineSelecting features, building and optimizing classifiers using machine learning and deep learning techniquesnew lineCollaborates with Data Engineers to enhance data collection and ingestion/curation techniques to include information that is relevant for building analytic systemsnew lineProcessing, cleansing, and verifying the integrity of data used for analysisnew lineDevelop processes and tools to monitor and analyze model performance and data accuracy. Life cycle management of predictive models.new lineAdherence to compliance procedures in accordance with regulatory standards, requirements, and policies. Managing and designing the reporting environment, including data sources security, and metadata.new lineJob Qualifications:new lineMaster s degree or PhD in Computer Science, Information management, Statistics or related field, with 3 to 5 years of experience in the Consumer or Healthcare industry manipulating data sets and building predictive models with focus on product developmentnew lineExperience in statistical modelling, machine learning, data mining, unstructured data analytics and natural language processing. Sound understanding of - Bayesian Modelling, Classification Models, Cluster Analysis, Neural Network, Nonparametric Methods, Multivariate Statistics, etc.new lineStrong hands on knowledge of ML techniques like regression algorithms, K-NN, Na ve Bayes, SVM and ensemble techniques like Random forest, AdaBoost etcnew lineHaving strong knowledge in unsupervised learning algorithms using Neural networks and Deep-Learningnew lineStrong knowledge in Data Wrangling and Exploration techniques to identify the patterns, trends and outliners.new lineDeep knowledge and practical experience with data science toolkits, such as NumPy, Pandas, scikit-learn or equivalentnew lineExperience with data visualization tools, such as QlikView, Matplotlib, seaborn or equivalent tools.new lineProficiency in using query languages, such as SQL, PL/SQLnew lineHands on experience in the one or more databases like Hadoop, AWS Redshift, Snowflake etc.new lineGood applied statistics skills, such as distributions, statistical testing, regression, etc.new lineGood ETL scripting and programming skills, such as Python, R or Scala to integrate developed solution into the proposition.new lineA team player capable of working and integrating across cross-functional team for implementing project requirements. Experience in technical requirements gathering and documentation.new lineAbility to work effectively and independently in a fast-paced global collaborative agile team environment with tight deadlinesnew lineA flexible, pragmatic and collaborative team player with innate ability to engage with stakeholders at all levels in the organization.new lineA self-starter with high levels of drive, energy, resilience and a desire for professional excellence with a passion for data and data sciencenew lineRoleClinical Research Associate/Scientistnew lineIndustry TypeMedical Services / Hospitalnew lineFunctional AreaMedical, Healthcare, R&D, Pharmaceuticals, Biotechnologynew lineEmployment TypeFull Time, Permanentnew lineRole CategoryR&Dnew lineEducationnew lineUG :Any Graduatenew linePG :Post Graduation Not Requirednew lineKey Skillsnew lineProduct managementComputer sciencemetadataMachine learningAgilePLSQLHealthcareQlikViewData miningPython',\n",
       " '--',\n",
       " 'Job descriptionnew line  Skillsnew lineRequired Skills: Data Science, Machine Learning, Deep Learning, Python, NLPnew lineDesired Skills: Computer Visionnew lineRoles and responsibilitiesnew lineExperience in Data Modelling, R, Python, SQL, Data Science, Machine Learning, Deep Learning, NLP, Statisticsnew lineHave ability to solve Business problems using Datanew lineShould possess extensive knowledge of and experience in applying data mining and machine learning techniques on large amount of datasetsnew lineHigh level of proficiency in statistical tools like R, Pythonnew lineCandidate will be expected to communicate analytical results in a way that is meaningful for business stakeholders and provides actionable insights.new lineHave the ability to discover new opportunities where advanced analytical techniques can be leveraged for solving business problemsnew lineGood to Havenew lineExpertise in programming languages like Java/C/C /Pythonnew lineExperience with relational databases and SQL is good to havenew lineExperience in audio and video analyticsnew lineRelevant experience in Big Data platforms like Hadoop eco-systemnew lineCome up with innovative algorithms and solutionsnew lineStaffing Type:Permanentnew lineRoleClinical Research Associate/Scientistnew lineIndustry TypeIT Services & Consultingnew lineFunctional AreaMedical, Healthcare, R&D, Pharmaceuticals, Biotechnologynew lineEmployment TypeFull Time, Permanentnew lineRole CategoryR&Dnew lineEducationnew lineUG :Any Graduatenew linePG :Any Postgraduatenew lineKey Skillsnew lineHospitalityNSEStaffingBfsiAnalyticalAgileData miningAnalyticsAutomotiveSQL',\n",
       " 'Job descriptionnew lineRequired Technical and Professional Expertisenew line• 6+ years of industry work experience in data scientist projectsnew line• Master’s degree or higher in Statistics/Math/Computer Science or related fieldnew line• Background in applied statistical modeling on large experimental or observational data setsnew line• Experience extracting data from a variety of sources, and a desire to expand those skills (working knowledge SQL is required, Spark is a plus)new line• Experience with one or more statistical or machine learning software such as R, Python, etc.new line• Must showcase past work through published articles/GitHub/social medianew linenew linePreferred Technical and Professional Expertisenew line• Knowledge of distributed computing systems, e.g. Cosmos, Spark, Hadoop, and relational database management systemnew line• PhD. in Statistics is preferrednew line• You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologiesnew line• Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to worknew line• Intuitive individual with an ability to manage change and proven time managementnew line• Proven interpersonal skills while contributing to team effort by accomplishing related results as needednew lineRoleData Analystnew lineIndustry TypeIT Services & Consultingnew lineFunctional AreaAnalytics & Business Intelligencenew lineEmployment TypeFull Time, Permanentnew lineRole CategoryAnalytics & BInew lineEducationnew lineUG :B.Sc in Maths, Statisticsnew linePG :MS/M.Sc(Science) in Maths, Statisticsnew lineDoctorate :Doctorate Not Requirednew lineKey Skillsnew lineRData scienceData analyticsSQLPython',\n",
       " '--',\n",
       " '--',\n",
       " 'Job descriptionnew lineRoles and Responsibilitiesnew lineRequirements :new linenew line- 6-9 years of strong experience in data mining, machine learning and statistical analysis.new linenew line- BS/ MS/ PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)new linenew line- Ability to lead and deliver in a fast-paced start-up environment.new linenew line- Fluency in tools such as Python/ R/ Matlab etc.new linenew line- Strong intuition for data and Keen aptitude on large scale data analysisnew linenew line- Excellent written and verbal communication skills.new linenew line- Ability to collaborate across teams and strong interpersonal skills.new lineRoleData Analystnew lineIndustry TypeIT Services & Consultingnew lineFunctional AreaAnalytics & Business Intelligencenew lineEmployment TypeFull Time, Permanentnew lineRole CategoryAnalytics & BInew lineEducationnew lineUG :B.Sc in Computers, Statisticsnew linePG :MS/M.Sc(Science) in Computers, Statisticsnew lineDoctorate :Ph.D/Doctorate in Statistics, Computersnew lineKey Skillsnew lineData ScienceRData ScientistData MiningStatistical AnalystMachine LearningMATLABPython',\n",
       " \"Job descriptionnew linenew lineJob description:new linenew lineSeeking senior data scientists for project-based roles that involve working on various projects.new linenew lineThe candidate must have experience in Python coding language and machine learning. The candidate will be working on a part-time basis and hours will be flexible based on the candidate's availability.new lineOpportunity to grow in a startup setting.new lineWhat you'll need:new lineB.Tech in CS or Statistics with demonstrable experience of over 5 years through publications/deployed solutions/projects.new lineM.Tech or Ph.D. in CS or Statistics with demonstrable experience of over 3 years through publications/deployed solutions/projects.new lineA deep understanding of applied statistical analysis and predictive modeling is desired.new lineThe candidate must have a thorough grasp of the theory and application of broad ML algorithms namely, but not limited to regression, SVM, Tree, Random Forests, Boosting, Neural Network, clustering, forecasting, deep learning, text analysis, etc.new lineIt is not expected that the candidate has actually worked on all these modules.new lineStrong proficiency in Python or R is necessarynew linenew lineRoleData Analystnew lineIndustry TypeIT Services & Consultingnew lineFunctional AreaAnalytics & Business Intelligencenew lineEmployment TypePart Time, Freelance/Homebasednew lineRole CategoryAnalytics & BInew lineEducationnew lineUG :Any Graduatenew lineKey Skillsnew linePredictive ModelingRAlgorithmsSVMClusteringMachine LearningStatistical AnalysisStatisticsDeep LearningPython\",\n",
       " 'Job descriptionnew lineRoles and Responsibilitiesnew lineWe are looking for someone who would be responsible for analyzing data and providing business insights. As a Data Scientist your responsibilities will include understanding the business problem and experimenting with different modelling architectures to create the best possible setup from model performance as well as computational performance. To do this job successfully, you need exceptional skills in Machine Learning and Programming. Your ultimate goal will be to find the best data-based solution for the problem at hand.new lineMoreover, you are expected to learn fast and deliver quickly in a fast-paced startup environment. If you thrive on ambiguity and are a problem solver and yet deliver value to clients, feel free to reach out to us.new lineWe are looking ONLY FOR SELF DRIVEN INDIVIDUALS with a desire to excel in Data Science Domain.new lineUnderstanding business objectives and developing models that help to achieve them, along with metrics to track their progressnew lineDevelop and maintain robust data processing pipelines and reproducible modeling pipelinesnew lineBuild mathematical models to solve various problems ranging from Time Series forecasting to Neural Networks and ensure seamless deployment in production pipelines.new lineAnalyze experimental results, iterate and refine models to create significant business impactnew lineFollow strict coding standards and other software engineering best practicesnew linenew linenew lineDesired Candidate Profilenew lineProven experience as a Data Scientist or similar rolenew lineStrong SQL, R/Python Skillsnew lineShould have familiarity with Machine Learning Models and fundamentals in Forecasting and Optimization Techniquesnew lineShould have strong mathematical background & analytical bent of mindnew lineStrong Problem-Solving Abilitynew lineAbility to communicate well in a highly collaborative team environment, consisting of both technical and non-technical personnelnew lineReliable self-starter that is capable of working with a high degree of autonomynew linenew linenew linePerks and Benefitsnew linenew lineNeenOpal is a global management consulting firm with a unique and specialized focus on Data Science.new lineWe provide services across the whole value chain of an organization - Digital Strategy, Sales & Marketing, Supply Chain & Logistics as well as Finance. Youll have a blast doing it in our fun, passionate environment.new lineRoleData scientistnew lineIndustry TypeManagement Consultingnew lineFunctional AreaIT Software - Othernew lineEmployment TypeFull Time, Permanentnew lineRole CategoryNot mentionednew lineEducationnew lineUG :Any Graduatenew linePG :Any Postgraduatenew lineKey Skillsnew lineData SciencePythonSQLnew lineExcelSoftware EngineeringProblem SolvingNeural NetworksTime SeriesData AnalysisBusiness InsightsData ProcessingMachine Learningnew lineSkills highlighted with ‘‘ are preferred keyskills']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "job_desc=[]\n",
    "for i in job_opening_urls[:10]:\n",
    "    \n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        job_d=driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "        job_desc.append(job_d.text.replace(\"\\n\",\"new line\"))\n",
    "    except:\n",
    "        job_desc.append(\"--\")\n",
    "\n",
    "job_desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--',\n",
       " 'Philips India Limited',\n",
       " '--',\n",
       " 'Happiest Minds Technologies Pvt.Ltd',\n",
       " 'AVE-Promagne',\n",
       " '--',\n",
       " '--',\n",
       " 'Wrackle Technologies Pvt Ltd',\n",
       " 'Shikvix',\n",
       " 'NeenOpal Intelligent Solutions Private Limited']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting company name and location\n",
    "company=[]\n",
    "location=[]\n",
    "for i in job_opening_urls[:10]:\n",
    "    \n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "         company_name=driver.find_element_by_xpath(\"//div[@class='jd-header-comp-name']/a\")\n",
    "         loc=driver.find_element_by_xpath(\"//span[@class='location ']/a\")\n",
    "         company.append(company_name.text)\n",
    "         location.append(loc.text)\n",
    "    except:\n",
    "         company.append(\"--\")\n",
    "         location.append(\"--\")\n",
    "            \n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--',\n",
       " 'Bangalore/Bengaluru',\n",
       " '--',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad',\n",
       " '--',\n",
       " '--',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "company2=[]\n",
    "location2=[]\n",
    "for i in job_opening_urls[:10]:\n",
    "    \n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "         company_name=driver.find_element_by_xpath(\"//div[@class='f14 lh18 alignJ']/p\")\n",
    "         loc=driver.find_element_by_xpath(\"//span[@class='slide-meta-loc pull-left']/a\")\n",
    "\n",
    "         company2.append(company_name.text)\n",
    "         location2.append(loc.text)\n",
    "    except:\n",
    "         company2.append(\"--\")\n",
    "         location2.append(\"--\")\n",
    "                                          \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IBM India Pvt. Limited',\n",
       " '--',\n",
       " 'IBM India Pvt. Limited',\n",
       " '--',\n",
       " '--',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " '--',\n",
       " '--',\n",
       " '--']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bengaluru',\n",
       " '--',\n",
       " 'Bengaluru',\n",
       " '--',\n",
       " '--',\n",
       " 'Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " '--',\n",
       " '--',\n",
       " '--']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IBM India Pvt. Limited',\n",
       " 'Philips India Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Happiest Minds Technologies Pvt.Ltd',\n",
       " 'AVE-Promagne',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Wrackle Technologies Pvt Ltd',\n",
       " 'Shikvix',\n",
       " 'NeenOpal Intelligent Solutions Private Limited']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging the two lists\n",
    "company_=[]\n",
    "list=[0,3,6,7]\n",
    "for i in list:\n",
    "    for j in range(0,10):\n",
    "        if(company[j]!=\"--\"):\n",
    "          company_.append(company[j]) \n",
    "        else:\n",
    "            if(company[j]!=company2[i]):\n",
    "                company_.append(company2[i])\n",
    "            else:\n",
    "                company_.append(company2[i+1])\n",
    "company_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LEAD DATA SCIENTIST BFSI',\n",
       " 'Associate Data Scientist',\n",
       " 'LEAD DATA SCIENTIST BFSI',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'Data Scientist (Python & SQL)',\n",
       " 'LEAD DATA SCIENTIST BFSI',\n",
       " 'LEAD DATA SCIENTIST BFSI',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Freelance Data Scientist Project Based',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job__=[]\n",
    "list=[0,3,6,7]\n",
    "for i in list:\n",
    "    for j in range(0,10):\n",
    "        if(job_titles[j]!=\"--\"):\n",
    "          job__.append(job_titles[j]) \n",
    "        else:\n",
    "            if(job_titles[j]!=job[i]):\n",
    "                job__.append(job[i])\n",
    "            else:\n",
    "                job__.append(job[i+1])\n",
    "job__[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location__=[]\n",
    "list=[0,3,6,7]\n",
    "for i in list:\n",
    "    for j in range(0,10):\n",
    "        if(location[j]!=\"--\"):\n",
    "          location__.append(location[j]) \n",
    "        else:\n",
    "            if(location[j]!=location2[i]):\n",
    "                location__.append(location2[i])\n",
    "            else:\n",
    "                location__.append(location2[i+1])\n",
    "location__[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc2=[]\n",
    "for i in job_opening_urls[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        jobdesc=driver.find_element_by_xpath(\"//div[@class='nConfig_textblock ']\")\n",
    "        job_desc2.append(jobdesc.text.replace(\"\\n\",\" new line: \"))\n",
    "    except:\n",
    "        job_desc2.append(\"--\")\n",
    "    job_desc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job Description new line: Introduction new line: Software Developers at IBM are the backbone of our strategic initiatives to design, code, test, and provide industry-leading solutions that make the world run today - planes and trains take off on time, bank transactions complete in the blink of an eye and the world remains safe because of the work our software developers do. Whether you are working on projects internally or for a client, software development is critical to the success of IBM and our clients worldwide. At IBM, you will use the latest software development tools, techniques and approaches and work with leading minds in the industry to build solutions you can be proud of. new line:  new line: Your Role and Responsibilities new line: IBM s Global Technology Services (GTS) business unit has embarked on a mission to be the most trusted partner to our clients and enable them with game changing technology backbone to drive competitive advantage. One of the most significant & challenging areas for our clients is Data. From identifying & capturing to curation & consumption - we would like to simplify, automate, and accelerate the data lifecycle within our client s myriad use cases. new line: To this effect we have launched specific offering(s) and are building out a team of passionate achievers to help us define, create, market & deliver data solutions to our clients. We are looking for a passionate Data Scientists with expertise in Machine Learning, who can contribute to deliver on this vision. This is a fun and fast paced environment, where developers are empowered to innovate and learn fast is our standard operating model. new line: As a Senior Data Scientist you will be at the forefront of this ride and get to work with end clients on a regular basis. You will be the face of GTS & evangelize the data science & ML solutions that we have to offer. You will create compelling value proposition and targeted content to significantly improve our chances of winning in the marketplace. You will defend IBM solutions and build trust with the client at all levels -operational to executive. You will help drive, qualify & close opportunities. You will be responsible for the execution and successful delivery of Data Science assignments. You will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users. You understand challenges in the BFSI domains & can discover new avenues to apply AI/ML solutions to solve these challenges. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have a distinct ability to identify and implement robust, efficient, and scalable solutions that leverage multiple techniques and/or technologies. You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment new line:  new line: Required Technical and Professional Expertise new line: As a leader in Data science organization, lead multiple scrum teams to deliver innovative ML solutions in BFSI space new line: PH.D or Master s degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance new line: Overall Data Science, Statistical Analysis, Data Analytics & Machine Learning experience of 10 years new line: 7 years of BFSI domain experience in implementing data science or AI solutions from exploration to production new line: 3 years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems new line: Expert understanding of ML Production deployments. Have atleast 3 years of experience in production grade ML design, development & deployment new line: Work closely with internal and external stakeholders, both technical and non-technical and help translate deep ML knowledge to stakeholders. new line: Work closely with ML engineering/Infrastructure team to help define the vision of ML training and ML inference platforms running on Cloud as well as On-prem new line: Mentor and grow Junior data scientists in the team on both DS modelling and software engineering skills new line: Expert ability to define Data Science model development & MLOps process, workflows, coding practices & DevOps practices new line: Extensive overview of applied methods in statistics, machine learning and artificial intelligence new line: Expert understanding of various AI/ML technology stacks including Cloud Based services new line: Help define the data science development workflows from coding and architecture best practices, data strategy, to ML training and Inference platforms new line: Demonstrated experience in creating AI/ML solutions within the BFSI space: new line: Banking: Credit, Risk, Customer Exp, Open Banking, Digital Banking, Cross-Sell, Up-Sell, Branch Ops, Treasury, Cards Business, SME Banking, Wealth Management new line: Insurance/Insurtech: Claims, Operations, Agency Development, Sales & Distribution, Customer Experience, Forecasting, Actuarial, Segmentation, Pricing new line: FS/Regtech: Compliance & Regulatory, Auto, STPI, Consumer Durables, Commercial, Mortgage new line: Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management new line: Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques new line: Coach and lead a team of other data scientists, engineers, and other stakeholders new line: Propose suitable technology stacks for projects to be deployed across cloud platforms and on-premise infrastructure. new line: Solid data management and statistical modelling skills: new line: Experience with Scala/Python, Scikit-learn, TensorFlow, Keras, NLTK, PyTorch etc new line: Experience with leveraging best practices conducting advanced analytics projects new line: Experience in distributed & scalable ML development. Good PoV on TinyML and Embedded AI/ML new line:  new line: Preferred Technical and Professional Expertise new line: Experience with open-source distributed data processing & ML frameworks new line: Experience working in a Linux environment new line: Experience working within a development team setup which is building product/services new line: Experience with presenting complex data science processes/information to non-data scientists new line: Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr new line: Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects new line: Strong experience in both classical ML modeling approaches and Deep learning based model approaches new line: Data analysis, reporting, visualization expertise and experience with tools such as Tableau, Alteryx, Python and R at scale new line: Good NLP knowledge and cloud experience preferred new line: Passion, Drive and Can-do attitude new line: Good communication skills new line: Willingness to thrive in ambiguous environments',\n",
       " '--',\n",
       " 'Job Description new line: Introduction new line: As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live. new line:  new line: Your Role and Responsibilities new line: Work with IBM Q Start team on active exploratory research engagements to prepare for future use case commercialization within specific industry new line: Engage and educate client data science teams to define promising areas for quantum exploration new line: Implement quantum approaches, which includes data pre-/post-processing, running numerics and visualizing data new line: Collaborate with industry and solutioning experts to design and shape experiments to demonstrate quantum-enabled advantage new line: Define best practices related to information architecture, including collection, integration, organization, analysis and visualization of data for quantum-enabled impact new line: Engage in practice development initiatives focused on building employee knowledge and skills in specific areas of expertise through coaching and development of training course material new line:  new line: Required Technical and Professional Expertise new line: PhD/Masters in STEM-related fields with knowledge in Quantum Computing. new line: 5 years of data engineering and data science experience new line: 2 years of consulting experience within specific industries with strong domain expertise and business acumen new line: Proficiency with classical approaches to machine learning and linear algebra, including Support Vector Machine (SVM) for linear categorization and Singular Value Decomposition (SVD) to reduce dimensionality of data new line: Familiar with Qiskit software, including Qiskit Aqua for domain applications and Qiskit Terra for quantum circuit design and optimization new line: Excellent ideation, facilitation and communications skills new line: Detail-oriented team player with strong interpersonal skills and ability to take a leadership role when necessary new line: Willingness to travel globally up to 40% once we return to a travel-safe environment. new line: English: Fluent new line:  new line: Preferred Technical and Professional Expertise new line: 2 years of experience in at least one of the industries, with knowledge of industry trends, R&D areas, and computationally intensive processes (e.g. optimization) new line: Familiarity with Qiskit',\n",
       " '--',\n",
       " '--',\n",
       " 'Job Description new line: Introduction new line: As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live. new line:  new line: Your Role and Responsibilities new line: Data Science Consultants are adept across data science techniques using open source tools to solve varied use cases for our clients new line: They work to build strong, enduring relationships with client staff based on innovation, trust and service excellence. new line: They are accountable for successful delivery of complex data science engagements adhering to client s requirements and timelines new line: They learn constantly and lead adoption of emerging technologies and approaches in their processes benefiting the client & IBM overall. new line:  new line: Required Technical and Professional Expertise new line: BTech (with 8 years of relevant experience) or Masters (with 6 years of relevant experience) in Operations Research, Applied Mathematics/ Statistics/ Econometrics, Electrical or Systems Engineering, Physics or similar highly quantitative field new line: Strong ability to transform business requirements into data science formulations and implement the solutions in an efficient and scalable fashion new line: Sound understanding of data science concepts, model development & performance tuning processes as well as coding, version control and CI/CD best practices new line: Demonstrated extensive experience in building and deploying production quality models in a live digital environment using data pipelines and ML Ops frameworks including handling model drift, retraining and version control lifecycle new line: Highly skilled in Python and various data science related libraries of Python including TensorFlow, Keras, Sci-Kit Lean, Pandas, Numpy and PySpark new line: Experience in Convolutional Neural Network / Computer Vision projects using TensorFlow, PyTorch and leveraging public / open-source libraries (VGG16, ImageNet, YOLO, OpenCV, etc) as well as ability to tweak, modify these CNN architectures when required for a specific business problem. new line: Demonstrated ability of scoping, executing and scaling multiple data science deliverables on their own new line: Must have worked in developing and deploying models using more than one cloud platform (AWS, Azure, GCP, IBM) new line: Ability to handle multiple projects as an individual contributor and as a lead / mentor to other team members managed directly or indirectly on a project / assignment new line: Excellent interpersonal and stakeholder management skills including ability to interact and present to senior stakeholders',\n",
       " 'Job Description new line: As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live. new line:  new line: Your Role and Responsibilities new line: Data Science Consultants are adept across data science techniques using open source tools to solve varied use cases for our clients new line: They work to build strong, enduring relationships with client staff based on innovation, trust and service excellence. new line: They are accountable for successful delivery of complex data science engagements adhering to client s requirements and timelines new line: They learn constantly and lead adoption of emerging technologies and approaches in their processes benefiting the client & IBM overall. new line: Required Technical and Professional Expertise new line: BTech (with 8 years of relevant experience) or Masters (with 6 years of relevant experience) in Operations Research, Applied Mathematics/ Statistics/ Econometrics, Electrical or Systems Engineering, Physics or similar highly quantitative field new line: Strong ability to transform business requirements into data science formulations and implement the solutions in an efficient and scalable fashion new line: Sound understanding of data science concepts, model development & performance tuning processes as well as coding, version control and CI/CD best practices new line: Demonstrated extensive experience in building and deploying production quality models in a live digital environment using data pipelines and ML Ops frameworks including handling model drift, retraining and version control lifecycle new line: Highly skilled in Python and various data science related libraries of Python including TensorFlow, Keras, Sci-Kit Lean, Pandas, Numpy and PySpark new line: Experience in Convolutional Neural Network / Computer Vision projects using TensorFlow, PyTorch and leveraging public / open-source libraries (VGG16, ImageNet, YOLO, OpenCV, etc) as well as ability to tweak, modify these CNN architectures when required for a specific business problem. new line: Demonstrated ability of scoping, executing and scaling multiple data science deliverables on their own new line: Must have worked in developing and deploying models using more than one cloud platform (AWS, Azure, GCP, IBM) new line: Ability to handle multiple projects as an individual contributor and as a lead / mentor to other team members managed directly or indirectly on a project / assignment new line: Excellent interpersonal and stakeholder management skills including ability to interact and present to senior stakeholders',\n",
       " '--',\n",
       " '--',\n",
       " '--']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_desc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job Description new line: Introduction new line: Software Developers at IBM are the backbone of our strategic initiatives to design, code, test, and provide industry-leading solutions that make the world run today - planes and trains take off on time, bank transactions complete in the blink of an eye and the world remains safe because of the work our software developers do. Whether you are working on projects internally or for a client, software development is critical to the success of IBM and our clients worldwide. At IBM, you will use the latest software development tools, techniques and approaches and work with leading minds in the industry to build solutions you can be proud of. new line:  new line: Your Role and Responsibilities new line: IBM s Global Technology Services (GTS) business unit has embarked on a mission to be the most trusted partner to our clients and enable them with game changing technology backbone to drive competitive advantage. One of the most significant & challenging areas for our clients is Data. From identifying & capturing to curation & consumption - we would like to simplify, automate, and accelerate the data lifecycle within our client s myriad use cases. new line: To this effect we have launched specific offering(s) and are building out a team of passionate achievers to help us define, create, market & deliver data solutions to our clients. We are looking for a passionate Data Scientists with expertise in Machine Learning, who can contribute to deliver on this vision. This is a fun and fast paced environment, where developers are empowered to innovate and learn fast is our standard operating model. new line: As a Senior Data Scientist you will be at the forefront of this ride and get to work with end clients on a regular basis. You will be the face of GTS & evangelize the data science & ML solutions that we have to offer. You will create compelling value proposition and targeted content to significantly improve our chances of winning in the marketplace. You will defend IBM solutions and build trust with the client at all levels -operational to executive. You will help drive, qualify & close opportunities. You will be responsible for the execution and successful delivery of Data Science assignments. You will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users. You understand challenges in the BFSI domains & can discover new avenues to apply AI/ML solutions to solve these challenges. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have a distinct ability to identify and implement robust, efficient, and scalable solutions that leverage multiple techniques and/or technologies. You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment new line:  new line: Required Technical and Professional Expertise new line: As a leader in Data science organization, lead multiple scrum teams to deliver innovative ML solutions in BFSI space new line: PH.D or Master s degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance new line: Overall Data Science, Statistical Analysis, Data Analytics & Machine Learning experience of 10 years new line: 7 years of BFSI domain experience in implementing data science or AI solutions from exploration to production new line: 3 years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems new line: Expert understanding of ML Production deployments. Have atleast 3 years of experience in production grade ML design, development & deployment new line: Work closely with internal and external stakeholders, both technical and non-technical and help translate deep ML knowledge to stakeholders. new line: Work closely with ML engineering/Infrastructure team to help define the vision of ML training and ML inference platforms running on Cloud as well as On-prem new line: Mentor and grow Junior data scientists in the team on both DS modelling and software engineering skills new line: Expert ability to define Data Science model development & MLOps process, workflows, coding practices & DevOps practices new line: Extensive overview of applied methods in statistics, machine learning and artificial intelligence new line: Expert understanding of various AI/ML technology stacks including Cloud Based services new line: Help define the data science development workflows from coding and architecture best practices, data strategy, to ML training and Inference platforms new line: Demonstrated experience in creating AI/ML solutions within the BFSI space: new line: Banking: Credit, Risk, Customer Exp, Open Banking, Digital Banking, Cross-Sell, Up-Sell, Branch Ops, Treasury, Cards Business, SME Banking, Wealth Management new line: Insurance/Insurtech: Claims, Operations, Agency Development, Sales & Distribution, Customer Experience, Forecasting, Actuarial, Segmentation, Pricing new line: FS/Regtech: Compliance & Regulatory, Auto, STPI, Consumer Durables, Commercial, Mortgage new line: Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management new line: Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques new line: Coach and lead a team of other data scientists, engineers, and other stakeholders new line: Propose suitable technology stacks for projects to be deployed across cloud platforms and on-premise infrastructure. new line: Solid data management and statistical modelling skills: new line: Experience with Scala/Python, Scikit-learn, TensorFlow, Keras, NLTK, PyTorch etc new line: Experience with leveraging best practices conducting advanced analytics projects new line: Experience in distributed & scalable ML development. Good PoV on TinyML and Embedded AI/ML new line:  new line: Preferred Technical and Professional Expertise new line: Experience with open-source distributed data processing & ML frameworks new line: Experience working in a Linux environment new line: Experience working within a development team setup which is building product/services new line: Experience with presenting complex data science processes/information to non-data scientists new line: Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr new line: Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects new line: Strong experience in both classical ML modeling approaches and Deep learning based model approaches new line: Data analysis, reporting, visualization expertise and experience with tools such as Tableau, Alteryx, Python and R at scale new line: Good NLP knowledge and cloud experience preferred new line: Passion, Drive and Can-do attitude new line: Good communication skills new line: Willingness to thrive in ambiguous environments',\n",
       " 'Job descriptionnew lineUse predictive modeling to increase and optimize customer experiences, revenue generation, campaign optimization and other business outcomesnew lineWork with product management to develop data use cases and embed predictive models in workflows on resource constrained platforms and cloud enabled.new lineSelecting features, building and optimizing classifiers using machine learning and deep learning techniquesnew lineCollaborates with Data Engineers to enhance data collection and ingestion/curation techniques to include information that is relevant for building analytic systemsnew lineProcessing, cleansing, and verifying the integrity of data used for analysisnew lineDevelop processes and tools to monitor and analyze model performance and data accuracy. Life cycle management of predictive models.new lineAdherence to compliance procedures in accordance with regulatory standards, requirements, and policies. Managing and designing the reporting environment, including data sources security, and metadata.new lineJob Qualifications:new lineMaster s degree or PhD in Computer Science, Information management, Statistics or related field, with 3 to 5 years of experience in the Consumer or Healthcare industry manipulating data sets and building predictive models with focus on product developmentnew lineExperience in statistical modelling, machine learning, data mining, unstructured data analytics and natural language processing. Sound understanding of - Bayesian Modelling, Classification Models, Cluster Analysis, Neural Network, Nonparametric Methods, Multivariate Statistics, etc.new lineStrong hands on knowledge of ML techniques like regression algorithms, K-NN, Na ve Bayes, SVM and ensemble techniques like Random forest, AdaBoost etcnew lineHaving strong knowledge in unsupervised learning algorithms using Neural networks and Deep-Learningnew lineStrong knowledge in Data Wrangling and Exploration techniques to identify the patterns, trends and outliners.new lineDeep knowledge and practical experience with data science toolkits, such as NumPy, Pandas, scikit-learn or equivalentnew lineExperience with data visualization tools, such as QlikView, Matplotlib, seaborn or equivalent tools.new lineProficiency in using query languages, such as SQL, PL/SQLnew lineHands on experience in the one or more databases like Hadoop, AWS Redshift, Snowflake etc.new lineGood applied statistics skills, such as distributions, statistical testing, regression, etc.new lineGood ETL scripting and programming skills, such as Python, R or Scala to integrate developed solution into the proposition.new lineA team player capable of working and integrating across cross-functional team for implementing project requirements. Experience in technical requirements gathering and documentation.new lineAbility to work effectively and independently in a fast-paced global collaborative agile team environment with tight deadlinesnew lineA flexible, pragmatic and collaborative team player with innate ability to engage with stakeholders at all levels in the organization.new lineA self-starter with high levels of drive, energy, resilience and a desire for professional excellence with a passion for data and data sciencenew lineRoleClinical Research Associate/Scientistnew lineIndustry TypeMedical Services / Hospitalnew lineFunctional AreaMedical, Healthcare, R&D, Pharmaceuticals, Biotechnologynew lineEmployment TypeFull Time, Permanentnew lineRole CategoryR&Dnew lineEducationnew lineUG :Any Graduatenew linePG :Post Graduation Not Requirednew lineKey Skillsnew lineProduct managementComputer sciencemetadataMachine learningAgilePLSQLHealthcareQlikViewData miningPython',\n",
       " 'Job Description new line: Introduction new line: Software Developers at IBM are the backbone of our strategic initiatives to design, code, test, and provide industry-leading solutions that make the world run today - planes and trains take off on time, bank transactions complete in the blink of an eye and the world remains safe because of the work our software developers do. Whether you are working on projects internally or for a client, software development is critical to the success of IBM and our clients worldwide. At IBM, you will use the latest software development tools, techniques and approaches and work with leading minds in the industry to build solutions you can be proud of. new line:  new line: Your Role and Responsibilities new line: IBM s Global Technology Services (GTS) business unit has embarked on a mission to be the most trusted partner to our clients and enable them with game changing technology backbone to drive competitive advantage. One of the most significant & challenging areas for our clients is Data. From identifying & capturing to curation & consumption - we would like to simplify, automate, and accelerate the data lifecycle within our client s myriad use cases. new line: To this effect we have launched specific offering(s) and are building out a team of passionate achievers to help us define, create, market & deliver data solutions to our clients. We are looking for a passionate Data Scientists with expertise in Machine Learning, who can contribute to deliver on this vision. This is a fun and fast paced environment, where developers are empowered to innovate and learn fast is our standard operating model. new line: As a Senior Data Scientist you will be at the forefront of this ride and get to work with end clients on a regular basis. You will be the face of GTS & evangelize the data science & ML solutions that we have to offer. You will create compelling value proposition and targeted content to significantly improve our chances of winning in the marketplace. You will defend IBM solutions and build trust with the client at all levels -operational to executive. You will help drive, qualify & close opportunities. You will be responsible for the execution and successful delivery of Data Science assignments. You will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users. You understand challenges in the BFSI domains & can discover new avenues to apply AI/ML solutions to solve these challenges. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have a distinct ability to identify and implement robust, efficient, and scalable solutions that leverage multiple techniques and/or technologies. You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment new line:  new line: Required Technical and Professional Expertise new line: As a leader in Data science organization, lead multiple scrum teams to deliver innovative ML solutions in BFSI space new line: PH.D or Master s degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance new line: Overall Data Science, Statistical Analysis, Data Analytics & Machine Learning experience of 10 years new line: 7 years of BFSI domain experience in implementing data science or AI solutions from exploration to production new line: 3 years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems new line: Expert understanding of ML Production deployments. Have atleast 3 years of experience in production grade ML design, development & deployment new line: Work closely with internal and external stakeholders, both technical and non-technical and help translate deep ML knowledge to stakeholders. new line: Work closely with ML engineering/Infrastructure team to help define the vision of ML training and ML inference platforms running on Cloud as well as On-prem new line: Mentor and grow Junior data scientists in the team on both DS modelling and software engineering skills new line: Expert ability to define Data Science model development & MLOps process, workflows, coding practices & DevOps practices new line: Extensive overview of applied methods in statistics, machine learning and artificial intelligence new line: Expert understanding of various AI/ML technology stacks including Cloud Based services new line: Help define the data science development workflows from coding and architecture best practices, data strategy, to ML training and Inference platforms new line: Demonstrated experience in creating AI/ML solutions within the BFSI space: new line: Banking: Credit, Risk, Customer Exp, Open Banking, Digital Banking, Cross-Sell, Up-Sell, Branch Ops, Treasury, Cards Business, SME Banking, Wealth Management new line: Insurance/Insurtech: Claims, Operations, Agency Development, Sales & Distribution, Customer Experience, Forecasting, Actuarial, Segmentation, Pricing new line: FS/Regtech: Compliance & Regulatory, Auto, STPI, Consumer Durables, Commercial, Mortgage new line: Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management new line: Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques new line: Coach and lead a team of other data scientists, engineers, and other stakeholders new line: Propose suitable technology stacks for projects to be deployed across cloud platforms and on-premise infrastructure. new line: Solid data management and statistical modelling skills: new line: Experience with Scala/Python, Scikit-learn, TensorFlow, Keras, NLTK, PyTorch etc new line: Experience with leveraging best practices conducting advanced analytics projects new line: Experience in distributed & scalable ML development. Good PoV on TinyML and Embedded AI/ML new line:  new line: Preferred Technical and Professional Expertise new line: Experience with open-source distributed data processing & ML frameworks new line: Experience working in a Linux environment new line: Experience working within a development team setup which is building product/services new line: Experience with presenting complex data science processes/information to non-data scientists new line: Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr new line: Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects new line: Strong experience in both classical ML modeling approaches and Deep learning based model approaches new line: Data analysis, reporting, visualization expertise and experience with tools such as Tableau, Alteryx, Python and R at scale new line: Good NLP knowledge and cloud experience preferred new line: Passion, Drive and Can-do attitude new line: Good communication skills new line: Willingness to thrive in ambiguous environments',\n",
       " 'Job descriptionnew line  Skillsnew lineRequired Skills: Data Science, Machine Learning, Deep Learning, Python, NLPnew lineDesired Skills: Computer Visionnew lineRoles and responsibilitiesnew lineExperience in Data Modelling, R, Python, SQL, Data Science, Machine Learning, Deep Learning, NLP, Statisticsnew lineHave ability to solve Business problems using Datanew lineShould possess extensive knowledge of and experience in applying data mining and machine learning techniques on large amount of datasetsnew lineHigh level of proficiency in statistical tools like R, Pythonnew lineCandidate will be expected to communicate analytical results in a way that is meaningful for business stakeholders and provides actionable insights.new lineHave the ability to discover new opportunities where advanced analytical techniques can be leveraged for solving business problemsnew lineGood to Havenew lineExpertise in programming languages like Java/C/C /Pythonnew lineExperience with relational databases and SQL is good to havenew lineExperience in audio and video analyticsnew lineRelevant experience in Big Data platforms like Hadoop eco-systemnew lineCome up with innovative algorithms and solutionsnew lineStaffing Type:Permanentnew lineRoleClinical Research Associate/Scientistnew lineIndustry TypeIT Services & Consultingnew lineFunctional AreaMedical, Healthcare, R&D, Pharmaceuticals, Biotechnologynew lineEmployment TypeFull Time, Permanentnew lineRole CategoryR&Dnew lineEducationnew lineUG :Any Graduatenew linePG :Any Postgraduatenew lineKey Skillsnew lineHospitalityNSEStaffingBfsiAnalyticalAgileData miningAnalyticsAutomotiveSQL',\n",
       " 'Job descriptionnew lineRequired Technical and Professional Expertisenew line• 6+ years of industry work experience in data scientist projectsnew line• Master’s degree or higher in Statistics/Math/Computer Science or related fieldnew line• Background in applied statistical modeling on large experimental or observational data setsnew line• Experience extracting data from a variety of sources, and a desire to expand those skills (working knowledge SQL is required, Spark is a plus)new line• Experience with one or more statistical or machine learning software such as R, Python, etc.new line• Must showcase past work through published articles/GitHub/social medianew linenew linePreferred Technical and Professional Expertisenew line• Knowledge of distributed computing systems, e.g. Cosmos, Spark, Hadoop, and relational database management systemnew line• PhD. in Statistics is preferrednew line• You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologiesnew line• Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to worknew line• Intuitive individual with an ability to manage change and proven time managementnew line• Proven interpersonal skills while contributing to team effort by accomplishing related results as needednew lineRoleData Analystnew lineIndustry TypeIT Services & Consultingnew lineFunctional AreaAnalytics & Business Intelligencenew lineEmployment TypeFull Time, Permanentnew lineRole CategoryAnalytics & BInew lineEducationnew lineUG :B.Sc in Maths, Statisticsnew linePG :MS/M.Sc(Science) in Maths, Statisticsnew lineDoctorate :Doctorate Not Requirednew lineKey Skillsnew lineRData scienceData analyticsSQLPython',\n",
       " 'Job Description new line: Introduction new line: Software Developers at IBM are the backbone of our strategic initiatives to design, code, test, and provide industry-leading solutions that make the world run today - planes and trains take off on time, bank transactions complete in the blink of an eye and the world remains safe because of the work our software developers do. Whether you are working on projects internally or for a client, software development is critical to the success of IBM and our clients worldwide. At IBM, you will use the latest software development tools, techniques and approaches and work with leading minds in the industry to build solutions you can be proud of. new line:  new line: Your Role and Responsibilities new line: IBM s Global Technology Services (GTS) business unit has embarked on a mission to be the most trusted partner to our clients and enable them with game changing technology backbone to drive competitive advantage. One of the most significant & challenging areas for our clients is Data. From identifying & capturing to curation & consumption - we would like to simplify, automate, and accelerate the data lifecycle within our client s myriad use cases. new line: To this effect we have launched specific offering(s) and are building out a team of passionate achievers to help us define, create, market & deliver data solutions to our clients. We are looking for a passionate Data Scientists with expertise in Machine Learning, who can contribute to deliver on this vision. This is a fun and fast paced environment, where developers are empowered to innovate and learn fast is our standard operating model. new line: As a Senior Data Scientist you will be at the forefront of this ride and get to work with end clients on a regular basis. You will be the face of GTS & evangelize the data science & ML solutions that we have to offer. You will create compelling value proposition and targeted content to significantly improve our chances of winning in the marketplace. You will defend IBM solutions and build trust with the client at all levels -operational to executive. You will help drive, qualify & close opportunities. You will be responsible for the execution and successful delivery of Data Science assignments. You will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users. You understand challenges in the BFSI domains & can discover new avenues to apply AI/ML solutions to solve these challenges. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have a distinct ability to identify and implement robust, efficient, and scalable solutions that leverage multiple techniques and/or technologies. You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment new line:  new line: Required Technical and Professional Expertise new line: As a leader in Data science organization, lead multiple scrum teams to deliver innovative ML solutions in BFSI space new line: PH.D or Master s degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance new line: Overall Data Science, Statistical Analysis, Data Analytics & Machine Learning experience of 10 years new line: 7 years of BFSI domain experience in implementing data science or AI solutions from exploration to production new line: 3 years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems new line: Expert understanding of ML Production deployments. Have atleast 3 years of experience in production grade ML design, development & deployment new line: Work closely with internal and external stakeholders, both technical and non-technical and help translate deep ML knowledge to stakeholders. new line: Work closely with ML engineering/Infrastructure team to help define the vision of ML training and ML inference platforms running on Cloud as well as On-prem new line: Mentor and grow Junior data scientists in the team on both DS modelling and software engineering skills new line: Expert ability to define Data Science model development & MLOps process, workflows, coding practices & DevOps practices new line: Extensive overview of applied methods in statistics, machine learning and artificial intelligence new line: Expert understanding of various AI/ML technology stacks including Cloud Based services new line: Help define the data science development workflows from coding and architecture best practices, data strategy, to ML training and Inference platforms new line: Demonstrated experience in creating AI/ML solutions within the BFSI space: new line: Banking: Credit, Risk, Customer Exp, Open Banking, Digital Banking, Cross-Sell, Up-Sell, Branch Ops, Treasury, Cards Business, SME Banking, Wealth Management new line: Insurance/Insurtech: Claims, Operations, Agency Development, Sales & Distribution, Customer Experience, Forecasting, Actuarial, Segmentation, Pricing new line: FS/Regtech: Compliance & Regulatory, Auto, STPI, Consumer Durables, Commercial, Mortgage new line: Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management new line: Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques new line: Coach and lead a team of other data scientists, engineers, and other stakeholders new line: Propose suitable technology stacks for projects to be deployed across cloud platforms and on-premise infrastructure. new line: Solid data management and statistical modelling skills: new line: Experience with Scala/Python, Scikit-learn, TensorFlow, Keras, NLTK, PyTorch etc new line: Experience with leveraging best practices conducting advanced analytics projects new line: Experience in distributed & scalable ML development. Good PoV on TinyML and Embedded AI/ML new line:  new line: Preferred Technical and Professional Expertise new line: Experience with open-source distributed data processing & ML frameworks new line: Experience working in a Linux environment new line: Experience working within a development team setup which is building product/services new line: Experience with presenting complex data science processes/information to non-data scientists new line: Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr new line: Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects new line: Strong experience in both classical ML modeling approaches and Deep learning based model approaches new line: Data analysis, reporting, visualization expertise and experience with tools such as Tableau, Alteryx, Python and R at scale new line: Good NLP knowledge and cloud experience preferred new line: Passion, Drive and Can-do attitude new line: Good communication skills new line: Willingness to thrive in ambiguous environments',\n",
       " 'Job Description new line: Introduction new line: Software Developers at IBM are the backbone of our strategic initiatives to design, code, test, and provide industry-leading solutions that make the world run today - planes and trains take off on time, bank transactions complete in the blink of an eye and the world remains safe because of the work our software developers do. Whether you are working on projects internally or for a client, software development is critical to the success of IBM and our clients worldwide. At IBM, you will use the latest software development tools, techniques and approaches and work with leading minds in the industry to build solutions you can be proud of. new line:  new line: Your Role and Responsibilities new line: IBM s Global Technology Services (GTS) business unit has embarked on a mission to be the most trusted partner to our clients and enable them with game changing technology backbone to drive competitive advantage. One of the most significant & challenging areas for our clients is Data. From identifying & capturing to curation & consumption - we would like to simplify, automate, and accelerate the data lifecycle within our client s myriad use cases. new line: To this effect we have launched specific offering(s) and are building out a team of passionate achievers to help us define, create, market & deliver data solutions to our clients. We are looking for a passionate Data Scientists with expertise in Machine Learning, who can contribute to deliver on this vision. This is a fun and fast paced environment, where developers are empowered to innovate and learn fast is our standard operating model. new line: As a Senior Data Scientist you will be at the forefront of this ride and get to work with end clients on a regular basis. You will be the face of GTS & evangelize the data science & ML solutions that we have to offer. You will create compelling value proposition and targeted content to significantly improve our chances of winning in the marketplace. You will defend IBM solutions and build trust with the client at all levels -operational to executive. You will help drive, qualify & close opportunities. You will be responsible for the execution and successful delivery of Data Science assignments. You will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users. You understand challenges in the BFSI domains & can discover new avenues to apply AI/ML solutions to solve these challenges. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have a distinct ability to identify and implement robust, efficient, and scalable solutions that leverage multiple techniques and/or technologies. You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment new line:  new line: Required Technical and Professional Expertise new line: As a leader in Data science organization, lead multiple scrum teams to deliver innovative ML solutions in BFSI space new line: PH.D or Master s degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance new line: Overall Data Science, Statistical Analysis, Data Analytics & Machine Learning experience of 10 years new line: 7 years of BFSI domain experience in implementing data science or AI solutions from exploration to production new line: 3 years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems new line: Expert understanding of ML Production deployments. Have atleast 3 years of experience in production grade ML design, development & deployment new line: Work closely with internal and external stakeholders, both technical and non-technical and help translate deep ML knowledge to stakeholders. new line: Work closely with ML engineering/Infrastructure team to help define the vision of ML training and ML inference platforms running on Cloud as well as On-prem new line: Mentor and grow Junior data scientists in the team on both DS modelling and software engineering skills new line: Expert ability to define Data Science model development & MLOps process, workflows, coding practices & DevOps practices new line: Extensive overview of applied methods in statistics, machine learning and artificial intelligence new line: Expert understanding of various AI/ML technology stacks including Cloud Based services new line: Help define the data science development workflows from coding and architecture best practices, data strategy, to ML training and Inference platforms new line: Demonstrated experience in creating AI/ML solutions within the BFSI space: new line: Banking: Credit, Risk, Customer Exp, Open Banking, Digital Banking, Cross-Sell, Up-Sell, Branch Ops, Treasury, Cards Business, SME Banking, Wealth Management new line: Insurance/Insurtech: Claims, Operations, Agency Development, Sales & Distribution, Customer Experience, Forecasting, Actuarial, Segmentation, Pricing new line: FS/Regtech: Compliance & Regulatory, Auto, STPI, Consumer Durables, Commercial, Mortgage new line: Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management new line: Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques new line: Coach and lead a team of other data scientists, engineers, and other stakeholders new line: Propose suitable technology stacks for projects to be deployed across cloud platforms and on-premise infrastructure. new line: Solid data management and statistical modelling skills: new line: Experience with Scala/Python, Scikit-learn, TensorFlow, Keras, NLTK, PyTorch etc new line: Experience with leveraging best practices conducting advanced analytics projects new line: Experience in distributed & scalable ML development. Good PoV on TinyML and Embedded AI/ML new line:  new line: Preferred Technical and Professional Expertise new line: Experience with open-source distributed data processing & ML frameworks new line: Experience working in a Linux environment new line: Experience working within a development team setup which is building product/services new line: Experience with presenting complex data science processes/information to non-data scientists new line: Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr new line: Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects new line: Strong experience in both classical ML modeling approaches and Deep learning based model approaches new line: Data analysis, reporting, visualization expertise and experience with tools such as Tableau, Alteryx, Python and R at scale new line: Good NLP knowledge and cloud experience preferred new line: Passion, Drive and Can-do attitude new line: Good communication skills new line: Willingness to thrive in ambiguous environments',\n",
       " 'Job descriptionnew lineRoles and Responsibilitiesnew lineRequirements :new linenew line- 6-9 years of strong experience in data mining, machine learning and statistical analysis.new linenew line- BS/ MS/ PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)new linenew line- Ability to lead and deliver in a fast-paced start-up environment.new linenew line- Fluency in tools such as Python/ R/ Matlab etc.new linenew line- Strong intuition for data and Keen aptitude on large scale data analysisnew linenew line- Excellent written and verbal communication skills.new linenew line- Ability to collaborate across teams and strong interpersonal skills.new lineRoleData Analystnew lineIndustry TypeIT Services & Consultingnew lineFunctional AreaAnalytics & Business Intelligencenew lineEmployment TypeFull Time, Permanentnew lineRole CategoryAnalytics & BInew lineEducationnew lineUG :B.Sc in Computers, Statisticsnew linePG :MS/M.Sc(Science) in Computers, Statisticsnew lineDoctorate :Ph.D/Doctorate in Statistics, Computersnew lineKey Skillsnew lineData ScienceRData ScientistData MiningStatistical AnalystMachine LearningMATLABPython',\n",
       " \"Job descriptionnew linenew lineJob description:new linenew lineSeeking senior data scientists for project-based roles that involve working on various projects.new linenew lineThe candidate must have experience in Python coding language and machine learning. The candidate will be working on a part-time basis and hours will be flexible based on the candidate's availability.new lineOpportunity to grow in a startup setting.new lineWhat you'll need:new lineB.Tech in CS or Statistics with demonstrable experience of over 5 years through publications/deployed solutions/projects.new lineM.Tech or Ph.D. in CS or Statistics with demonstrable experience of over 3 years through publications/deployed solutions/projects.new lineA deep understanding of applied statistical analysis and predictive modeling is desired.new lineThe candidate must have a thorough grasp of the theory and application of broad ML algorithms namely, but not limited to regression, SVM, Tree, Random Forests, Boosting, Neural Network, clustering, forecasting, deep learning, text analysis, etc.new lineIt is not expected that the candidate has actually worked on all these modules.new lineStrong proficiency in Python or R is necessarynew linenew lineRoleData Analystnew lineIndustry TypeIT Services & Consultingnew lineFunctional AreaAnalytics & Business Intelligencenew lineEmployment TypePart Time, Freelance/Homebasednew lineRole CategoryAnalytics & BInew lineEducationnew lineUG :Any Graduatenew lineKey Skillsnew linePredictive ModelingRAlgorithmsSVMClusteringMachine LearningStatistical AnalysisStatisticsDeep LearningPython\",\n",
       " 'Job descriptionnew lineRoles and Responsibilitiesnew lineWe are looking for someone who would be responsible for analyzing data and providing business insights. As a Data Scientist your responsibilities will include understanding the business problem and experimenting with different modelling architectures to create the best possible setup from model performance as well as computational performance. To do this job successfully, you need exceptional skills in Machine Learning and Programming. Your ultimate goal will be to find the best data-based solution for the problem at hand.new lineMoreover, you are expected to learn fast and deliver quickly in a fast-paced startup environment. If you thrive on ambiguity and are a problem solver and yet deliver value to clients, feel free to reach out to us.new lineWe are looking ONLY FOR SELF DRIVEN INDIVIDUALS with a desire to excel in Data Science Domain.new lineUnderstanding business objectives and developing models that help to achieve them, along with metrics to track their progressnew lineDevelop and maintain robust data processing pipelines and reproducible modeling pipelinesnew lineBuild mathematical models to solve various problems ranging from Time Series forecasting to Neural Networks and ensure seamless deployment in production pipelines.new lineAnalyze experimental results, iterate and refine models to create significant business impactnew lineFollow strict coding standards and other software engineering best practicesnew linenew linenew lineDesired Candidate Profilenew lineProven experience as a Data Scientist or similar rolenew lineStrong SQL, R/Python Skillsnew lineShould have familiarity with Machine Learning Models and fundamentals in Forecasting and Optimization Techniquesnew lineShould have strong mathematical background & analytical bent of mindnew lineStrong Problem-Solving Abilitynew lineAbility to communicate well in a highly collaborative team environment, consisting of both technical and non-technical personnelnew lineReliable self-starter that is capable of working with a high degree of autonomynew linenew linenew linePerks and Benefitsnew linenew lineNeenOpal is a global management consulting firm with a unique and specialized focus on Data Science.new lineWe provide services across the whole value chain of an organization - Digital Strategy, Sales & Marketing, Supply Chain & Logistics as well as Finance. Youll have a blast doing it in our fun, passionate environment.new lineRoleData scientistnew lineIndustry TypeManagement Consultingnew lineFunctional AreaIT Software - Othernew lineEmployment TypeFull Time, Permanentnew lineRole CategoryNot mentionednew lineEducationnew lineUG :Any Graduatenew linePG :Any Postgraduatenew lineKey Skillsnew lineData SciencePythonSQLnew lineExcelSoftware EngineeringProblem SolvingNeural NetworksTime SeriesData AnalysisBusiness InsightsData ProcessingMachine Learningnew lineSkills highlighted with ‘‘ are preferred keyskills']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description=[]\n",
    "list=[0,3,6,7]\n",
    "for i in list:\n",
    "    for j in range(0,10):\n",
    "        if(job_desc[j]!=\"--\"):\n",
    "          description.append(job_desc[j]) \n",
    "        else:\n",
    "            if(job_desc[j]!=job_desc2[i]):\n",
    "                description.append(job_desc2[i])\n",
    "            else:\n",
    "                description.append(job_desc2[i+1])\n",
    "description[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATAFRAME FOR THE SCRAPED DATA: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>FULL_JOB_DESC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LEAD DATA SCIENTIST BFSI</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Description new line: Introduction new lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job descriptionnew lineUse predictive modeling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LEAD DATA SCIENTIST BFSI</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Description new line: Introduction new lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>Happiest Minds Technologies Pvt.Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job descriptionnew line  Skillsnew lineRequire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (Python &amp; SQL)</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Job descriptionnew lineRequired Technical and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LEAD DATA SCIENTIST BFSI</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Description new line: Introduction new lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LEAD DATA SCIENTIST BFSI</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Description new line: Introduction new lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job descriptionnew lineRoles and Responsibilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Freelance Data Scientist Project Based</td>\n",
       "      <td>Shikvix</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job descriptionnew linenew lineJob description...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NeenOpal Intelligent Solutions Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job descriptionnew lineRoles and Responsibilit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           JOB_TITLE  \\\n",
       "0                           LEAD DATA SCIENTIST BFSI   \n",
       "1                           Associate Data Scientist   \n",
       "2                           LEAD DATA SCIENTIST BFSI   \n",
       "3                              SENIOR DATA SCIENTIST   \n",
       "4                      Data Scientist (Python & SQL)   \n",
       "5                           LEAD DATA SCIENTIST BFSI   \n",
       "6                           LEAD DATA SCIENTIST BFSI   \n",
       "7  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "8             Freelance Data Scientist Project Based   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                     COMPANY_NAME                LOCATION  \\\n",
       "0                          IBM India Pvt. Limited               Bengaluru   \n",
       "1                           Philips India Limited     Bangalore/Bengaluru   \n",
       "2                          IBM India Pvt. Limited               Bengaluru   \n",
       "3             Happiest Minds Technologies Pvt.Ltd     Bangalore/Bengaluru   \n",
       "4                                    AVE-Promagne  Hyderabad/Secunderabad   \n",
       "5                          IBM India Pvt. Limited               Bengaluru   \n",
       "6                          IBM India Pvt. Limited               Bengaluru   \n",
       "7                    Wrackle Technologies Pvt Ltd     Bangalore/Bengaluru   \n",
       "8                                         Shikvix     Bangalore/Bengaluru   \n",
       "9  NeenOpal Intelligent Solutions Private Limited     Bangalore/Bengaluru   \n",
       "\n",
       "                                       FULL_JOB_DESC  \n",
       "0  Job Description new line: Introduction new lin...  \n",
       "1  Job descriptionnew lineUse predictive modeling...  \n",
       "2  Job Description new line: Introduction new lin...  \n",
       "3  Job descriptionnew line  Skillsnew lineRequire...  \n",
       "4  Job descriptionnew lineRequired Technical and ...  \n",
       "5  Job Description new line: Introduction new lin...  \n",
       "6  Job Description new line: Introduction new lin...  \n",
       "7  Job descriptionnew lineRoles and Responsibilit...  \n",
       "8  Job descriptionnew linenew lineJob description...  \n",
       "9  Job descriptionnew lineRoles and Responsibilit...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.DataFrame()\n",
    "df2[\"JOB_TITLE\"]=job__[:10]\n",
    "df2[\"COMPANY_NAME\"]=company_[:10]\n",
    "df2[\"LOCATION\"]=location__[:10]\n",
    "df2[\"FULL_JOB_DESC\"]=description[:10]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_xpath(\"//input[@class='sugInp']\")\n",
    "search_job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying location and salary filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter=driver.find_elements_by_xpath(\"//div[@class='mt-8 chckBoxCont']//span\")\n",
    "\n",
    "\n",
    "for i in loc_filter :\n",
    "    if (i.text=='Delhi / NCR'):\n",
    "        i.click()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sal_filter=driver.find_elements_by_xpath(\"//div[@class='mt-8 chckBoxCont']//span\")\n",
    "for i in sal_filter:\n",
    "    if(i.text=='3-6 Lakhs'):\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Only Fresher / Data Scientist / Data Analyst / Analytics - MNC Jobs',\n",
       " 'Data Analyst/Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist / Data Analyst / Business Analytics - MNC Jobs Freshers',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist / Data Analyst',\n",
       " 'Data Scientist - WFH - MIND Infotech',\n",
       " 'Immediate Openings For Data Scientist For Wipro C2H',\n",
       " 'Data Scientist/ Machine Learning Engineer',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist-immediate Joiners',\n",
       " 'Junior Data Scientists & Engineers',\n",
       " 'Data Scientist - Machine Learning/ NLP',\n",
       " 'Data Scientist Internship',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Hiring Data Scientist Develope || IDS Infotech LTD || (Permanent WFH)',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job=[]\n",
    "for i in job_title:\n",
    "    job.append(i.text)\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GABA Consultancy services',\n",
       " 'Skillenable Fintech Private Limited',\n",
       " 'PROCESS NINE TECHNOLOGIES PVT.LTD.',\n",
       " 'GABA Consultancy services',\n",
       " 'R Systems International Ltd.',\n",
       " 'CARS24',\n",
       " 'MOTHERSONSUMI INFOTECH & DESIGNS LIMITED',\n",
       " 'IDESLABS PRIVATE LIMITED',\n",
       " 'Creative Hands HR Consultancy',\n",
       " 'Kusum Healthcare Pvt. Ltd.',\n",
       " 'Quikruit Consulting LLP',\n",
       " 'PY Consultancy',\n",
       " 'TalPro',\n",
       " 'iHackers Inc',\n",
       " 'Fractal Analytics',\n",
       " 'inVentiv International Pharma Services Pvt. Ltd.',\n",
       " 'iNICU',\n",
       " 'IDS Infotech Ltd.',\n",
       " 'Sentieo',\n",
       " 'BlackBuck']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company=[]\n",
    "for i in comp_name:\n",
    "    company.append(i.text)\n",
    "    \n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-0 Yrs',\n",
       " '2-5 Yrs',\n",
       " '1-3 Yrs',\n",
       " '0-0 Yrs',\n",
       " '3-6 Yrs',\n",
       " '1-5 Yrs',\n",
       " '3-7 Yrs',\n",
       " '5-10 Yrs',\n",
       " '0-0 Yrs',\n",
       " '4-6 Yrs',\n",
       " '2-5 Yrs',\n",
       " '0-3 Yrs',\n",
       " '2-6 Yrs',\n",
       " '0-1 Yrs',\n",
       " '3-7 Yrs',\n",
       " '3-6 Yrs',\n",
       " '1-5 Yrs',\n",
       " '5-10 Yrs',\n",
       " '2-7 Yrs',\n",
       " '3-7 Yrs']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_req=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "experience=[]\n",
    "for i in exp_req:\n",
    "    experience.append(i.text)\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Noida, New Delhi, Gurgaon/Gurugram',\n",
       " 'Noida',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Mohali/SAS Nagar, Hyderabad/Secunderabad, Ahmedabad, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru',\n",
       " 'Delhi / NCR(Okhla)',\n",
       " 'Noida',\n",
       " 'New Delhi, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'New Delhi',\n",
       " 'Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Delhi',\n",
       " 'Chandigarh, Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Delhi',\n",
       " 'Gurgaon, Bengaluru']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "location=[]\n",
    "for i in loc:\n",
    "    location.append(i.text)\n",
    "    \n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating DataFrame for the scraped data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>EXPERIENCE_REQUIRED</th>\n",
       "      <th>JOB_LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst/Data Scientist</td>\n",
       "      <td>Skillenable Fintech Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PROCESS NINE TECHNOLOGIES PVT.LTD.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Data Analyst / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>CARS24</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - WFH - MIND Infotech</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru, Delhi / NC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Immediate Openings For Data Scientist For Wipr...</td>\n",
       "      <td>IDESLABS PRIVATE LIMITED</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist/ Machine Learning Engineer</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Mohali/SAS Nagar, Hyderabad/Secunderabad, Ahme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kusum Healthcare Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>Delhi / NCR(Okhla)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           JOB_TITLE  \\\n",
       "0  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "1                        Data Analyst/Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3  Data Scientist / Data Analyst / Business Analy...   \n",
       "4                                     Data Scientist   \n",
       "5                      Data Scientist / Data Analyst   \n",
       "6               Data Scientist - WFH - MIND Infotech   \n",
       "7  Immediate Openings For Data Scientist For Wipr...   \n",
       "8          Data Scientist/ Machine Learning Engineer   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                               COMPANY_NAME EXPERIENCE_REQUIRED  \\\n",
       "0                 GABA Consultancy services             0-0 Yrs   \n",
       "1       Skillenable Fintech Private Limited             2-5 Yrs   \n",
       "2        PROCESS NINE TECHNOLOGIES PVT.LTD.             1-3 Yrs   \n",
       "3                 GABA Consultancy services             0-0 Yrs   \n",
       "4              R Systems International Ltd.             3-6 Yrs   \n",
       "5                                    CARS24             1-5 Yrs   \n",
       "6  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED             3-7 Yrs   \n",
       "7                  IDESLABS PRIVATE LIMITED            5-10 Yrs   \n",
       "8             Creative Hands HR Consultancy             0-0 Yrs   \n",
       "9                Kusum Healthcare Pvt. Ltd.             4-6 Yrs   \n",
       "\n",
       "                                        JOB_LOCATION  \n",
       "0               Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "1  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "2                                   Gurgaon/Gurugram  \n",
       "3                 Noida, New Delhi, Gurgaon/Gurugram  \n",
       "4                                              Noida  \n",
       "5                                   Gurgaon/Gurugram  \n",
       "6  Pune, Chennai, Bangalore/Bengaluru, Delhi / NC...  \n",
       "7                                   Gurgaon/Gurugram  \n",
       "8  Mohali/SAS Nagar, Hyderabad/Secunderabad, Ahme...  \n",
       "9                                 Delhi / NCR(Okhla)  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame()\n",
    "df3[\"JOB_TITLE\"]=job[:10]\n",
    "df3[\"COMPANY_NAME\"]=company[:10]\n",
    "df3[\"EXPERIENCE_REQUIRED\"]=experience[:10]\n",
    "df3[\"JOB_LOCATION\"]=location[:10]\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION-5\n",
    "SCRAPING DATA FROM GLASSDOOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching glassdoor url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximizing the windows\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping location and job_title element and sending keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//input[@id='sc.keyword']\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_btn=driver.find_element_by_xpath(\"//input[@id='sc.location']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_btn.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the search button's web element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//span[@class='css-8zxfjs']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"00cf675053e85501495afdd7266b119e\", element=\"c29259d0-859d-4462-855f-466e83a648f2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"00cf675053e85501495afdd7266b119e\", element=\"358025ca-5eb0-4429-81b6-78531fdd2ac1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"00cf675053e85501495afdd7266b119e\", element=\"7aa5c979-bcc6-4f6d-afa6-1a4508356a76\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"00cf675053e85501495afdd7266b119e\", element=\"43a0fde4-88da-4efe-85ef-33ec3de24e86\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"00cf675053e85501495afdd7266b119e\", element=\"64ff7958-5c1d-47cf-8dd3-cf1cde8ffe69\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"00cf675053e85501495afdd7266b119e\", element=\"f8c8aed2-1bd5-4c8f-ba30-d70b4e1a1c51\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"00cf675053e85501495afdd7266b119e\", element=\"2855e15b-d599-416d-8df6-4224b51026ec\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"00cf675053e85501495afdd7266b119e\", element=\"58bce804-bd75-4eea-b75d-7497c8654e72\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"00cf675053e85501495afdd7266b119e\", element=\"123bf7b7-f6ac-4c3e-b9a2-a1600ca434ab\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"00cf675053e85501495afdd7266b119e\", element=\"69a7d9c5-d471-4bba-bdb3-905540c3a487\")>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title=driver.find_elements_by_xpath(\"//a[@class='jobLink job-search-key-1rd3saf eigr9kq1']/span\")\n",
    "job_title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analytics part time job/internship at Noida',\n",
       " 'Associate Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Management Trainee – Data Science',\n",
       " 'Analyst – Data Science',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist Intern',\n",
       " 'Data Scientist: Artificial Intelligence',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using driver.execute script command to scroll down the page\n",
    "job_titles=[]\n",
    "for i in job_title[:10]:\n",
    "    driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "    \n",
    "    job_titles.append(i.text)\n",
    "    \n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the name of the companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "company=driver.find_elements_by_xpath(\"//a[@class=' job-search-key-l2wjgv e1n63ojh0 jobLink']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noisy Lion',\n",
       " 'Liberin Technologies Private Limited',\n",
       " 'AlgoScale Technologies Private Limited',\n",
       " 'Grail Insights',\n",
       " 'Grail Insights',\n",
       " 'Innovacer',\n",
       " 'Salasar New Age Technologies',\n",
       " 'IBM',\n",
       " 'Techlive',\n",
       " 'Lenskart']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name=[]\n",
    "for i in company[:10]:\n",
    "    driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "    \n",
    "    company_name.append(i.text)\n",
    "    \n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping time lapsed since the ad was posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-17n8uzw']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24h', '30d+', '14d', '24h', '24h', '30d+', '30d+', '19d', '30d+', '2d']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_since_posted=[]\n",
    "for i in days[:10]:\n",
    "    driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "    \n",
    "    time_since_posted.append(i.text)\n",
    "    \n",
    "time_since_posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping company rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=driver.find_elements_by_xpath(\"//span[@class=' job-search-key-srfzj0 e1cjmv6j0']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.9', '3.5', '3.5', '3.8', '3.9', '3.6', '3.8', '3.3', '4.1', '3.8']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "for i in ratings[:10]:\n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        rating.append(i.text)\n",
    "    except:\n",
    "        rating.append(\"Not Available\")\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a DataFrame for the stored data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=pd.DataFrame()\n",
    "df4[\"INDEX\"]=range(1,11)\n",
    "df4[\"COMPANY_NAME\"]=company_name[:10]\n",
    "df4[\"RATING\"]=rating[:10]\n",
    "df4[\"TIME_SINCE_POSTED\"]=time_since_posted[:10]\n",
    "df4.set_index('INDEX',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>RATING</th>\n",
       "      <th>TIME_SINCE_POSTED</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noisy Lion</td>\n",
       "      <td>3.9</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>3.5</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AlgoScale Technologies Private Limited</td>\n",
       "      <td>3.5</td>\n",
       "      <td>14d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grail Insights</td>\n",
       "      <td>3.8</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Grail Insights</td>\n",
       "      <td>3.9</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Innovacer</td>\n",
       "      <td>3.6</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IBM</td>\n",
       "      <td>3.3</td>\n",
       "      <td>19d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>4.1</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lenskart</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 COMPANY_NAME RATING TIME_SINCE_POSTED\n",
       "INDEX                                                                 \n",
       "1                                  Noisy Lion    3.9               24h\n",
       "2        Liberin Technologies Private Limited    3.5              30d+\n",
       "3      AlgoScale Technologies Private Limited    3.5               14d\n",
       "4                              Grail Insights    3.8               24h\n",
       "5                              Grail Insights    3.9               24h\n",
       "6                                   Innovacer    3.6              30d+\n",
       "7                Salasar New Age Technologies    3.8              30d+\n",
       "8                                         IBM    3.3               19d\n",
       "9                                    Techlive    4.1              30d+\n",
       "10                                   Lenskart    3.8                2d"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION-6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging into flipkart and providing necessary information\n",
    "email_btn=driver.find_element_by_xpath(\"//input[@class='_2IX_2- VJZDxU']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "email_btn=driver.find_element_by_xpath(\"//input[@class='_2IX_2- VJZDxU']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_btn.send_keys('9625708656')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "password_btn=driver.find_element_by_xpath(\"//input[@class='_2IX_2- _3mctLh VJZDxU']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the password has been hidden due to privacy concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "password_btn.send_keys(\"******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_btn=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2HKlqd _3AWRsL']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_items=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_items.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating functions to scrape the similar attributes from different pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_brand_name(url):\n",
    "    brand=[]\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        brand_el=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        for i in brand_el:\n",
    "            \n",
    "            brand.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "            \n",
    "        return brand\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"exception raised\",e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_product_des(url):\n",
    "    product_des=[]\n",
    "    driver.get(url)\n",
    "    product_el=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    for i in product_el:\n",
    "        try:\n",
    "            product_des.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            product_des.append(\"--\")\n",
    "        \n",
    "    return product_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_price(url):\n",
    "    price=[]\n",
    "    driver.get(url)\n",
    "    price_el=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    \n",
    "    for i in price_el:\n",
    "        try:\n",
    "            price.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "            \n",
    "        except:\n",
    "            price.append(\"--\")\n",
    "        \n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_discount(url):\n",
    "    discount=[]\n",
    "    driver.get(url)\n",
    "    \n",
    "    discount_el=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "        \n",
    "    for i in discount_el:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            discount.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            discount.append(\"--\")\n",
    "        \n",
    "    return discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list=[]\n",
    "product_list=[]\n",
    "discount_list=[]\n",
    "price_list=[]\n",
    "urls='https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page='\n",
    "for i in ['1','2','3']:\n",
    "\n",
    "   url= urls+i\n",
    "   time.sleep(5)\n",
    "   brand=scrape_brand_name(url)\n",
    "   brand_list.extend(brand) \n",
    "   product=scrape_product_des(url)\n",
    "   product_list.extend(product)\n",
    "   discount=scrape_discount(url)\n",
    "   discount_list.extend(discount)\n",
    "   price=scrape_price(url)\n",
    "   price_list.extend(price) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[120, 118, 119, 120]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length=[len(brand_list),len(product_list),len(discount_list),len(price_list)]\n",
    "length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>PRODUCT_DESCRIPTION</th>\n",
       "      <th>DISCOUNT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Villain</td>\n",
       "      <td>Others Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>40% off</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized Sports Sunglasses (68)</td>\n",
       "      <td>50% off</td>\n",
       "      <td>₹1,234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>88% off</td>\n",
       "      <td>₹198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>88% off</td>\n",
       "      <td>₹295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>89% off</td>\n",
       "      <td>₹284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Re...</td>\n",
       "      <td>73% off</td>\n",
       "      <td>₹664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Oval Sunglasses (58)</td>\n",
       "      <td>72% off</td>\n",
       "      <td>₹398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>67% off</td>\n",
       "      <td>₹459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Mirrored Round Sunglasses (Free...</td>\n",
       "      <td>29% off</td>\n",
       "      <td>₹495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>83% off</td>\n",
       "      <td>₹1,415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                BRAND                                PRODUCT_DESCRIPTION  \\\n",
       "0             Villain             Others Wayfarer Sunglasses (Free Size)   \n",
       "1           ROYAL SON                   Polarized Sports Sunglasses (68)   \n",
       "2   SHAAH COLLECTIONS  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "3           Elligator                UV Protection Round Sunglasses (54)   \n",
       "4      kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...   \n",
       "..                ...                                                ...   \n",
       "95          ROYAL SON  UV Protection, Night Vision, Riding Glasses Re...   \n",
       "96     ROZZETTA CRAFT       UV Protection, Gradient Oval Sunglasses (58)   \n",
       "97              NuVew  by Lenskart Polarized, UV Protection Cat-eye S...   \n",
       "98             AISLIN  UV Protection, Mirrored Round Sunglasses (Free...   \n",
       "99          ROYAL SON              UV Protection Aviator Sunglasses (58)   \n",
       "\n",
       "   DISCOUNT   PRICE  \n",
       "0   40% off    ₹599  \n",
       "1   50% off  ₹1,234  \n",
       "2   88% off    ₹198  \n",
       "3   88% off    ₹295  \n",
       "4   89% off    ₹284  \n",
       "..      ...     ...  \n",
       "95  73% off    ₹664  \n",
       "96  72% off    ₹398  \n",
       "97  67% off    ₹459  \n",
       "98  29% off    ₹495  \n",
       "99  83% off  ₹1,415  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating DataFrame for the scraped Data\n",
    "import pandas as pd\n",
    "df5=pd.DataFrame()\n",
    "df5[\"BRAND\"]=brand_list[:100]\n",
    "df5[\"PRODUCT_DESCRIPTION\"]=product_list[:100]\n",
    "df5[\"DISCOUNT\"]=discount_list[:100]\n",
    "df5[\"PRICE\"]=price_list[:100]\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION-7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to\n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_btn=driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']/span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1='https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining functions to scrape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_rating():\n",
    "    rating=[]\n",
    "    driver.refresh()\n",
    "    rating_el=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    time.sleep(3)\n",
    "    for i in rating_el:\n",
    "        try:\n",
    "            rating.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            rating.append(\"--\")\n",
    "    return rating\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_review_summary():\n",
    "    review_sum=[]\n",
    "    driver.refresh()\n",
    "    rev_sum=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    time.sleep(3)\n",
    "    for i in rev_sum:\n",
    "        try:\n",
    "            review_sum.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            review_sum.append(\"--\")\n",
    "    return review_sum\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_full_review():\n",
    "    full_review=[]\n",
    "    driver.refresh()\n",
    "    rev_el=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div\")\n",
    "    time.sleep(3)\n",
    "    for i in rev_el:\n",
    "        try:\n",
    "            full_review.append(i.text.replace(\"\\n\",\"  New Line: \"))\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            full_review.append(\"--\")\n",
    "    return full_review\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "review_sum=[]\n",
    "full_review=[]\n",
    "length=len(rating)\n",
    "while(length<=100):\n",
    "    driver.refresh()\n",
    "    rating.extend(scrape_rating())\n",
    "    review_sum.extend(scrape_review_summary())\n",
    "    full_review.extend(scrape_full_review())\n",
    "    time.sleep(5)\n",
    "    length=len(rating)\n",
    "    next_btn=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "    next_btn.click()\n",
    "    \n",
    "len(review_sum)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the data was scraped properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[110, 110, 110]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_list=[len(full_review),len(rating),len(review_sum)]\n",
    "length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brilliant',\n",
       " 'Best in the market!',\n",
       " 'Simply awesome',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Brilliant',\n",
       " 'Best in the market!',\n",
       " 'Simply awesome',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Brilliant',\n",
       " 'Best in the market!',\n",
       " 'Simply awesome',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Brilliant',\n",
       " 'Best in the market!',\n",
       " 'Simply awesome',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Brilliant',\n",
       " 'Best in the market!',\n",
       " 'Simply awesome',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Brilliant',\n",
       " 'Best in the market!',\n",
       " 'Simply awesome',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Brilliant',\n",
       " 'Best in the market!',\n",
       " 'Simply awesome',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Brilliant',\n",
       " 'Best in the market!',\n",
       " 'Simply awesome',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Brilliant',\n",
       " 'Best in the market!',\n",
       " 'Simply awesome',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Brilliant',\n",
       " 'Best in the market!',\n",
       " 'Simply awesome',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Brilliant',\n",
       " 'Best in the market!',\n",
       " 'Simply awesome',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RATING</th>\n",
       "      <th>REVIEW_SUMMARY</th>\n",
       "      <th>FULL_REVIEW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  New Line:   New ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.  New Line...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RATING       REVIEW_SUMMARY  \\\n",
       "INDEX                               \n",
       "1          5            Brilliant   \n",
       "2          5  Best in the market!   \n",
       "3          5       Simply awesome   \n",
       "4          5     Perfect product!   \n",
       "5          5            Fabulous!   \n",
       "...      ...                  ...   \n",
       "96         5    Worth every penny   \n",
       "97         5        Great product   \n",
       "98         4          Good choice   \n",
       "99         5    Worth every penny   \n",
       "100        5   Highly recommended   \n",
       "\n",
       "                                             FULL_REVIEW  \n",
       "INDEX                                                     \n",
       "1      The Best Phone for the Money  New Line:   New ...  \n",
       "2      Great iPhone very snappy experience as apple k...  \n",
       "3      Really satisfied with the Product I received.....  \n",
       "4      Amazing phone with great cameras and better ba...  \n",
       "5      This is my first iOS phone. I am very happy wi...  \n",
       "...                                                  ...  \n",
       "96     Previously I was using one plus 3t it was a gr...  \n",
       "97     Amazing Powerful and Durable Gadget.  New Line...  \n",
       "98     So far it’s been an AMAZING experience coming ...  \n",
       "99     i11 is worthy to buy, too much happy with the ...  \n",
       "100    What a camera .....just awesome ..you can feel...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a DataFrame for the scraped data\n",
    "import pandas as pd\n",
    "df6=pd.DataFrame()\n",
    "df6[\"INDEX\"]=range(1,101)\n",
    "df6[\"RATING\"]=rating[:100]\n",
    "df6[\"REVIEW_SUMMARY\"]=review_sum[:100]\n",
    "df6[\"FULL_REVIEW\"]=full_review[:100]\n",
    "df6.set_index(\"INDEX\",inplace=True)\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data for first 100 sneakers you find when you visit flipkart.com and\n",
    "search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_btn=driver.find_element_by_xpath(\"//input[@class='_2IX_2- VJZDxU']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_btn.send_keys(\"9625708656\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "password_column=driver.find_element_by_xpath(\"//input[@class='_2IX_2- _3mctLh VJZDxU']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The password has been hidden due to privacy concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "password_column.send_keys(\"*******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_btn=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2HKlqd _3AWRsL']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_column=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_column.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating functions to scrape data\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_brand():\n",
    "    brand=[]\n",
    "    brand_el=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    time.sleep(3)\n",
    "    for i in brand_el:\n",
    "        try:\n",
    "            brand.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            brand.append(\"--\")\n",
    "    return brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_product_des():\n",
    "    product_des=[]\n",
    "    des_el=driver.find_elements_by_xpath(\"//a[@class='IRpwTa' or @class='IRpwTa _2-ICcC']\")\n",
    "    print(len(des_el))\n",
    "    time.sleep(3)\n",
    "    for i in des_el:\n",
    "        try:\n",
    "            product_des.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            product_des.append(\"--\")\n",
    "    return product_des\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_price():\n",
    "    price=[]\n",
    "    price_el=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    time.sleep(3)\n",
    "    for i in price_el:\n",
    "        try:\n",
    "            price.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            price.append(\"--\")\n",
    "            \n",
    "    return price\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_discount():\n",
    "    discount=[]\n",
    "    discount_el=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "    time.sleep(3)\n",
    "    for i in discount_el:\n",
    "        try:\n",
    "            discount.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            discount.append(\"--\")\n",
    "            \n",
    "    return discount\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data using functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=[]\n",
    "product_des=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "length=len(brand)\n",
    "while(length<=100):\n",
    "    driver.refresh()\n",
    "    brand.extend(scrape_brand())\n",
    "    product_des.extend(scrape_product_des())\n",
    "    price.extend(scrape_price())\n",
    "    discount.extend(scrape_discount())\n",
    "    time.sleep(3)\n",
    "    next_btn=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "    next_btn.click()\n",
    "    length=len(brand)\n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[120, 120, 120, 120]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting the length of scraped attributes\n",
    "length_list=[len(brand),len(product_des),len(discount),len(price)]\n",
    "length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>PRODUCT_DESCRIPTION</th>\n",
       "      <th>DISCOUNT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pollachief</td>\n",
       "      <td>Casual Sneaker for Men Sneakers For Men</td>\n",
       "      <td>57% off</td>\n",
       "      <td>₹421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>56% off</td>\n",
       "      <td>₹1,699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>66% off</td>\n",
       "      <td>₹536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>86% off</td>\n",
       "      <td>₹474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>70% off</td>\n",
       "      <td>₹536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Vedboy</td>\n",
       "      <td>Feather Print New Spring Season White Shoes Me...</td>\n",
       "      <td>35% off</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ardeo</td>\n",
       "      <td>RAMBOW FUNKY SHOE FOR GYM OUTDOOR WALKING Snea...</td>\n",
       "      <td>71% off</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>VIPSJAZZY</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>60% off</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Arohi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>53% off</td>\n",
       "      <td>₹460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>U.S. POLO ASSN.</td>\n",
       "      <td>LEBRON 2.0 Sneakers For Men</td>\n",
       "      <td>40% off</td>\n",
       "      <td>₹2,399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       BRAND  \\\n",
       "INDEX                          \n",
       "1                 pollachief   \n",
       "2      HRX by Hrithik Roshan   \n",
       "3                     Chevit   \n",
       "4                     BRUTON   \n",
       "5                     Chevit   \n",
       "...                      ...   \n",
       "96                    Vedboy   \n",
       "97                     Ardeo   \n",
       "98                 VIPSJAZZY   \n",
       "99                     Arohi   \n",
       "100          U.S. POLO ASSN.   \n",
       "\n",
       "                                     PRODUCT_DESCRIPTION DISCOUNT   PRICE  \n",
       "INDEX                                                                      \n",
       "1                Casual Sneaker for Men Sneakers For Men  57% off    ₹421  \n",
       "2                                       Sneakers For Men  56% off  ₹1,699  \n",
       "3      Super Stylish & Trendy Combo Pack of 02 Pairs ...  66% off    ₹536  \n",
       "4      Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...  86% off    ₹474  \n",
       "5      Perfect & Affordable Combo Pack of 02 Pairs Sn...  70% off    ₹536  \n",
       "...                                                  ...      ...     ...  \n",
       "96     Feather Print New Spring Season White Shoes Me...  35% off    ₹449  \n",
       "97     RAMBOW FUNKY SHOE FOR GYM OUTDOOR WALKING Snea...  71% off    ₹449  \n",
       "98                                      Sneakers For Men  60% off    ₹399  \n",
       "99                                      Sneakers For Men  53% off    ₹460  \n",
       "100                          LEBRON 2.0 Sneakers For Men  40% off  ₹2,399  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating DataFrame for the scraped data\n",
    "import pandas as pd\n",
    "sneakers=pd.DataFrame()\n",
    "sneakers[\"INDEX\"]=range(1,101)\n",
    "sneakers[\"BRAND\"]=brand[:100]\n",
    "sneakers[\"PRODUCT_DESCRIPTION\"]=product_des[:100]\n",
    "sneakers[\"DISCOUNT\"]=discount[:100]\n",
    "sneakers[\"PRICE\"]=price[:100]\n",
    "sneakers.set_index(\"INDEX\",inplace=True)\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” ,Color filter to “Black”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since there is no \"Rs. 6649 to Rs. 13099” filter,using the nearest filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_filter=driver.find_elements_by_xpath(\"//label[@class='common-customCheckbox vertical-filters-label']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_filter[7].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_filter=driver.find_elements_by_xpath(\"//label[@class='common-customCheckbox']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_filter[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining functions for scraping\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_brand():\n",
    "    brand=[]\n",
    "    brand_el=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")\n",
    "    time.sleep(3)\n",
    "    for i in brand_el:\n",
    "        try:\n",
    "            brand.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            brand.append(\"--\")\n",
    "            \n",
    "    return brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_des():\n",
    "    description=[]\n",
    "    des_el=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\")\n",
    "    time.sleep(3)\n",
    "    for i in des_el:\n",
    "        try:\n",
    "            description.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            description.append(\"--\")\n",
    "    return description\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_price():\n",
    "    price=[]\n",
    "    price_el=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    time.sleep(3)\n",
    "    for i in price_el:\n",
    "        try:\n",
    "            price.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            price.append(\"--\")\n",
    "    return price\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=93.0.4577.63)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c5ec90dcde23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mbrand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscrape_brand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdescription\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscrape_des\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscrape_price\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-c1e29ead24e9>\u001b[0m in \u001b[0;36mscrape_des\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscrape_des\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdes_el\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[@class='product-productMetaInfo']/h4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdes_el\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0melements\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[contains(@class, 'foo')]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \"\"\"\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element_by_link_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1003\u001b[0m         \u001b[1;31m# Return empty list if driver returns null\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[1;31m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m         return self.execute(Command.FIND_ELEMENTS, {\n\u001b[0m\u001b[0;32m   1006\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m             'value': value})['value'] or []\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=93.0.4577.63)\n"
     ]
    }
   ],
   "source": [
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "length=len(brand)\n",
    "while(length<=100):\n",
    "    driver.refresh()\n",
    "    brand.extend(scrape_brand())\n",
    "    description.extend(scrape_des())\n",
    "    price.extend(scrape_price())\n",
    "    time.sleep(3)\n",
    "    length=len(brand)\n",
    "    next_btn=driver.find_element_by_xpath(\"//li[@class='pagination-next']/a\")\n",
    "    next_btn.click()\n",
    "    \n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the scraped data is clean and uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[150, 300, 150]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_list=[len(brand),len(description),len(price)]\n",
    "length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Men Air Zoom Structure Running',\n",
       " 'Men Driving Shoes',\n",
       " 'Men Cell Fraction Fade Running',\n",
       " 'Men Solid Leather Formal Slip-Ons',\n",
       " 'Men Velocity Nitro Running',\n",
       " 'Mesh Hybrid Fuego Running',\n",
       " 'Men BlackTraining or Gym Shoes',\n",
       " 'Men Charged Rogue 2.5 RFLCT',\n",
       " 'Men FUSE Training Shoes',\n",
       " 'Men HOVR Infinite Running',\n",
       " 'Women HOVR Sonic 4 Running',\n",
       " 'Women HOVR Sonic 4 FnRn',\n",
       " 'Men Tennis Shoes',\n",
       " \"Men BlazerLow '77 Sneakers\",\n",
       " 'Men Football Shoes',\n",
       " 'Men Jamming 2.0 Running Shoes',\n",
       " 'Men Solid Leather Formal Monk Shoes',\n",
       " 'Men Black Shoes',\n",
       " 'Women Eternity Nitro Running',\n",
       " 'Men Leather Slip-On Sneakers',\n",
       " 'Women Charged Assert 8 Running',\n",
       " 'Women Charged Impulse Shft',\n",
       " 'Men Loafers',\n",
       " 'Women Charged Vantage ClrShft',\n",
       " 'TREKKING 100 Boots',\n",
       " 'Men Solid Leather Formal Slip-Ons',\n",
       " 'GS SC 3Zero IV Basketball',\n",
       " 'Men Formal Derbys',\n",
       " 'Women GlideRide Running Shoes',\n",
       " 'Men Leather Formal Loafers',\n",
       " 'Men Liberate NITRO Running',\n",
       " 'Men HOVR Sonic STRT Tech Shoes',\n",
       " 'Women Running Shoes',\n",
       " 'Men Solid Formal Leather Derbys',\n",
       " 'Unisex Clyde Basketball Shoes',\n",
       " 'Men Leather Flat Boots',\n",
       " 'Men Solid Leather Formal Derbys',\n",
       " 'Women Charged Bandit 6 Running',\n",
       " 'Men Black Leather Loafers',\n",
       " 'Unisex FerrariRS-Fast Sneakers',\n",
       " 'Men Solid Loafers',\n",
       " 'Women Charged Rogue 2.5ClrSft',\n",
       " 'Unisex Ferrari Drift8 Sneakers',\n",
       " 'Unisex Mercedes F1 Sneakers',\n",
       " 'Unisex Colourblocked Sneakers',\n",
       " 'Scuderia Ferrari A3ROCAT Shoes',\n",
       " 'Men Leather Formal Loafers',\n",
       " 'Men Solid Formal Monks Shoes',\n",
       " 'Men Printed Slip-On Sneakers',\n",
       " 'Women BMW M Motorsport Shoes',\n",
       " 'Women BMW M Motorsport Shoes',\n",
       " 'Men Leather Formal Slip-Ons',\n",
       " 'Women Sneakers',\n",
       " 'Leather Block Sandals',\n",
       " 'Men Leather Formal Loafers',\n",
       " 'Women GlideRide Running Shoes',\n",
       " 'Men Solid Formal Leather Derbys',\n",
       " 'Men Solid Leather Formal Derbys',\n",
       " 'Women Leather Heeled Boots',\n",
       " 'Men Black Leather Loafers',\n",
       " 'Women Charged Breathe CLR SFT',\n",
       " 'Women Peep Toe Heels',\n",
       " 'Women Solid Leather Gladiators',\n",
       " 'Women Running Shoes',\n",
       " 'Women Liberate NITRO Running',\n",
       " 'Men Trekking Shoes',\n",
       " 'Men Wingtip Oxford Sneakers',\n",
       " 'Men GENERATION ZEROGRAND STITCHLITE',\n",
       " 'Leather Sneakers',\n",
       " 'Men Textured Sneakers',\n",
       " 'Women Air Zoom Running Shoes',\n",
       " 'Men Solid Leather Loafers',\n",
       " 'Men Textured Leather Loafers',\n",
       " 'Men Textured Leather Loafers',\n",
       " 'Men KD500 Running Shoe',\n",
       " 'Men Leather Formal Slip-Ons',\n",
       " 'Unisex BMW MMS RS-FastSneakers',\n",
       " 'Men Running Shoes',\n",
       " 'Men Black Running Sports Shoes',\n",
       " 'Men Black Walking Shoes',\n",
       " 'Men Walking Shoes',\n",
       " 'Men Running Shoes',\n",
       " 'Men Leather Formal Slip-Ons',\n",
       " 'Women Leather Heeled Boots',\n",
       " 'Women Leather Heeled Boots',\n",
       " 'Women Solid Leather Heels',\n",
       " 'Women Heeled Boots',\n",
       " 'Men Textured Leather Loafers',\n",
       " 'Women Leather Pumps',\n",
       " 'Men Solid Sneakers',\n",
       " 'Men Leather Driving Shoes',\n",
       " 'Women Solid Sneakers',\n",
       " 'Women Open Toe Flats',\n",
       " 'Men Solid Leather Formal Derbys',\n",
       " 'Men Solid Leather Formal Monks',\n",
       " 'Unisex Pacer Future Sneakers',\n",
       " 'Women Leather Pumps',\n",
       " 'Men Vomero 16 Running Shoes',\n",
       " 'Men ZOOM SPAN 3 Running Shoes',\n",
       " 'Men Solid Leather Formal Slip-Ons',\n",
       " 'Women Woven Design Sneakers',\n",
       " 'Men Solid Leather Formal Slip-Ons',\n",
       " 'Men Leather Formal Loafers',\n",
       " 'Men Leather Formal Loafers',\n",
       " 'Women LeatherSneakers',\n",
       " 'Women Solid Flat Boots',\n",
       " 'Men AIR MAX INFINITY Sneakers',\n",
       " 'Leather Block Peep Toes',\n",
       " 'Leather Heeled Boots',\n",
       " 'Leather Heeled Boots',\n",
       " 'Men Kaptir Super Sneakers',\n",
       " 'Leather Heeled Boots',\n",
       " 'Women Gladiators',\n",
       " 'Ustraa black',\n",
       " 'Women Open Toe Flats',\n",
       " 'Men Formal Leather Slip-Ons',\n",
       " \"Men Air Force 1 '07 Sneakers\",\n",
       " 'Women Block Heeled Boots',\n",
       " 'Platform Peep Toes with Buckles',\n",
       " 'Block Heeled Boots with Laser Cuts',\n",
       " 'Women Embellished Sandals',\n",
       " 'Men Patent Leather Sneakers',\n",
       " 'Women Mid-Top Flat Boots',\n",
       " 'Men Solid Leather Shoes',\n",
       " 'Men Textured Formal Leather Loafers',\n",
       " 'Men Textured Leather Formal Loafers',\n",
       " 'Men Textured Formal Leather Loafers',\n",
       " 'Women F1 Ridge Cat Sneakers',\n",
       " 'Men Solid Formal Leather Slip-On Shoes',\n",
       " 'Men Solid Leather Formal Derbys',\n",
       " 'Women Leather Sneakers',\n",
       " 'Unisex Rebound Future Trainers',\n",
       " 'Men Running Shoes',\n",
       " 'Men Textured Leather Loafers',\n",
       " 'Men Sneakers',\n",
       " 'Men Sneakers',\n",
       " 'HOVR Infinite 2 Running Shoes',\n",
       " 'Men Solid Leather Formal Brogues',\n",
       " 'Unisex Leather Trainers',\n",
       " 'Men Solid Leather Formal Derbys',\n",
       " 'Men Leather Chelsea Boots',\n",
       " 'Men Lightstrike Go Running',\n",
       " 'Men Leather Loafers',\n",
       " 'Men Zoom Winflo 8 Shoes',\n",
       " 'Unisex Colourblocked Sneakers',\n",
       " 'Men Solid Leather Formal Brogues',\n",
       " 'Unisex OP-1 PWRFrame Trainers',\n",
       " 'Men X9000L3 Running Shoes',\n",
       " 'Men Black Running Shoes',\n",
       " 'Unisex Black Sneakers']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_new=[]\n",
    "for i in range(0,300,2):\n",
    "    description_new.append(description[i])\n",
    "description_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>SHORT_DESCRIPTION</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Air Zoom Structure Running</td>\n",
       "      <td>Rs. 10295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Driving Shoes</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Cell Fraction Fade Running</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8099Rs. 8999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Velocity Nitro Running</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Pacer Future Sneakers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 7192Rs. 8990(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Vomero 16 Running Shoes</td>\n",
       "      <td>Rs. 13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men ZOOM SPAN 3 Running Shoes</td>\n",
       "      <td>Rs. 7195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 7990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      BRAND                  SHORT_DESCRIPTION  \\\n",
       "INDEX                                                            \n",
       "1                      Nike     Men Air Zoom Structure Running   \n",
       "2                      ALDO                  Men Driving Shoes   \n",
       "3                      Puma     Men Cell Fraction Fade Running   \n",
       "4              Hush Puppies  Men Solid Leather Formal Slip-Ons   \n",
       "5                      Puma         Men Velocity Nitro Running   \n",
       "...                     ...                                ...   \n",
       "96                     Puma       Unisex Pacer Future Sneakers   \n",
       "97     Heel & Buckle London                Women Leather Pumps   \n",
       "98                     Nike        Men Vomero 16 Running Shoes   \n",
       "99                     Nike      Men ZOOM SPAN 3 Running Shoes   \n",
       "100               J.FONTINI  Men Solid Leather Formal Slip-Ons   \n",
       "\n",
       "                           PRICE  \n",
       "INDEX                             \n",
       "1                      Rs. 10295  \n",
       "2                      Rs. 11999  \n",
       "3                       Rs. 6999  \n",
       "4      Rs. 8099Rs. 8999(10% OFF)  \n",
       "5                      Rs. 10999  \n",
       "...                          ...  \n",
       "96                      Rs. 6999  \n",
       "97     Rs. 7192Rs. 8990(20% OFF)  \n",
       "98                     Rs. 13495  \n",
       "99                      Rs. 7195  \n",
       "100                     Rs. 7990  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating Dataframe for the scraped data\n",
    "import pandas as pd\n",
    "myntra_shoes=pd.DataFrame()\n",
    "myntra_shoes[\"INDEX\"]=range(1,101)\n",
    "myntra_shoes[\"BRAND\"]=brand[:100]\n",
    "myntra_shoes[\"SHORT_DESCRIPTION\"]=description_new[:100]\n",
    "myntra_shoes[\"PRICE\"]=price[:100]\n",
    "myntra_shoes.set_index(\"INDEX\",inplace=True)\n",
    "myntra_shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\HP\\Downloads\\chromedriver_win32\\chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_col=driver.find_element_by_xpath(\"//input[@class='nav-input nav-progressive-attribute']\")\n",
    "search_col.send_keys('laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_elements_by_xpath(\"//input[@class='nav-input nav-progressive-attribute']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i7=driver.find_elements_by_xpath(\"//li[@id='p_n_feature_thirteen_browse-bin/12598163031']\")\n",
    "\n",
    "#for i in i7:\n",
    "    \n",
    "#print(i.text)\n",
    "#if(i.text)=='Intel Core i7':\n",
    "    #i.click()\n",
    "#break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the method explained in the doubt clearing session did not work\n",
    "#using the filters manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HP Envy 11th Gen Core i7 Processor 13.3-inch (33.78 cms) FHD Touchscreen Laptop (16GB/1TB SSD/Win 10/NVIDIA MX450 2GB/Natural Silver/1.3 kg), 13-ba1018TX',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i7-10510U 10th Gen Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg)(Without Webcam) XMA1904-AF',\n",
       " 'Lenovo IdeaPad S540 11th Gen Intel Core i7 13.3\" QHD IPS Thin & Light Laptop (16GB/512GB SSD/Windows 10/MS Office 2019/Intel Iris Xe Graphics/Iron Grey/1.28Kg), 82H1002CIN',\n",
       " 'ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 144Hz/3ms Gaming Laptop (8th Gen Intel Core i9-8950HK/64GB/2TB SSHD + 1.5TB NVMe SSD/Windows 10/GTX 1080 8GB Graphics/4.70 Kg), Aluminum',\n",
       " 'ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms) FHD 144Hz, Intel Core i7-11370H 11th Gen, RTX 3050 4GB Graphics Gaming Laptop (16GB RAM/512GB SSD/Windows 10/White/2 kg), FX516PC-HN062T',\n",
       " 'ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms) FHD 144Hz, Intel Core i7-11370H 11th Gen, RTX 3050 4GB Graphics Gaming Laptop (16GB RAM/512GB SSD/Windows 10/Gray/2 kg), FX516PC-HN063T',\n",
       " 'HP Pavilion 13(2021) 11th Gen Intel Core i7 Laptop, 16GB RAM, 1TB SSD, 13.3-inch(33.8 cm) FHD Screen, Win 10, MS Office, Ceramic White, 1.24 Kg (13-bb0078TU)',\n",
       " 'Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33.78cm) FHD IPS 400Nits 2-in1 Touch Convertible Laptop (16GB/1TB SSD/Win10/Office/Iris Xe Graphics/Backlit Kb/Black/997gms), 4ZR1D71993',\n",
       " 'Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 14\"(35.56cm) FHD IPS 2-in-1 Touchscreen Laptop(16GB/512GB SSD/Windows 10/MS Office/Lenovo Digital Pen/Fingerprint Reader/Graphite Grey/1.5Kg), 82HS0092IN',\n",
       " 'Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen 15.6\" FHD IPS 250Nits Gaming Laptop (8GB/512GB SSD/Win10/NVIDIA GTX 1650 4GB GDDR6 Graphics/120Hz/Onyx Black/2.2Kg), 81Y4019EIN']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_el=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "title=[]\n",
    "for i in title_el[:10]:\n",
    "    title.append(i.text)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,23,350',\n",
       " '57,990',\n",
       " '77,990',\n",
       " '5,56,524',\n",
       " '85,990',\n",
       " '84,990',\n",
       " '92,990',\n",
       " '1,07,990',\n",
       " '98,500',\n",
       " '73,990']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_el=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "price=[]\n",
    "for i in price_el[:10]:\n",
    "    price.append(i.text)\n",
    "price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.amazon.in/gp/slredirect/picassoRedirect.html/ref=pa_sp_atf_computers_sr_pg1_1?ie=UTF8&adId=A10081262K6KZOZ37JXYV&url=%2FHP-Processor-13-3-inch-Touchscreen-13-ba1018TX%2Fdp%2FB091FJ13Q5%2Fref%3Dsr_1_1_sspa%3Fdchild%3D1%26keywords%3Dlaptop%26qid%3D1631549097%26refinements%3Dp_n_feature_thirteen_browse-bin%253A12598163031%257C16757432031%26rnid%3D12598141031%26s%3Dcomputers%26sr%3D1-1-spons%26psc%3D1&qualifier=1631549097&id=4670954863775408&widgetName=sp_atf',\n",
       " 'https://www.amazon.in/Notebook-Horizon-i7-10510U-Graphics-XMA1904-AF/dp/B089DFJHZ8/ref=sr_1_2?dchild=1&keywords=laptop&qid=1631549097&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-2',\n",
       " 'https://www.amazon.in/Lenovo-IdeaPad-Windows-Graphics-82H1002CIN/dp/B094XJPQ6N/ref=sr_1_3?dchild=1&keywords=laptop&qid=1631549097&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-3',\n",
       " 'https://www.amazon.in/Asus-G703GI-E5148T-17-3-inch-i9-8950HK-Processor/dp/B07GRCW51K/ref=sr_1_4?dchild=1&keywords=laptop&qid=1631549097&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-4',\n",
       " 'https://www.amazon.in/ASUS-Dash-F15-15-6-inch-i7-11370H-FX516PC-HN062T/dp/B096KZ11KK/ref=sr_1_5?dchild=1&keywords=laptop&qid=1631549097&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-5',\n",
       " 'https://www.amazon.in/ASUS-Dash-F15-15-6-inch-i7-11370H-FX516PC-HN063T/dp/B096KVJ5PC/ref=sr_1_6?dchild=1&keywords=laptop&qid=1631549097&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-6',\n",
       " 'https://www.amazon.in/HP-Pavilion-13-3-inch-Ceramic-13-bb0078TU/dp/B09839P9XB/ref=sr_1_7?dchild=1&keywords=laptop&qid=1631549097&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-7',\n",
       " 'https://www.amazon.in/Fujitsu-33-78cm-Convertible-Graphics-4ZR1D71993/dp/B098P4M233/ref=sr_1_8?dchild=1&keywords=laptop&qid=1631549097&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-8',\n",
       " 'https://www.amazon.in/Lenovo-Touchscreen-Fingerprint-Graphite-82HS0092IN/dp/B08WRZQBQ6/ref=sr_1_9?dchild=1&keywords=laptop&qid=1631549097&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-9',\n",
       " 'https://www.amazon.in/Lenovo-IdeaPad-250Nits-Graphics-81Y4019EIN/dp/B097TZMG7R/ref=sr_1_10?dchild=1&keywords=laptop&qid=1631549097&refinements=p_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&rnid=12598141031&s=computers&sr=1-10']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "\n",
    "rating_url=[]\n",
    "for i in url2[:10]:\n",
    "    rating_url.append(i.get_attribute('href'))\n",
    "rating_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.1', '4.2', '4.3', '3.7', 'Previous', '3.0', '5.0', '4.1', '4.1', '4.4']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "rating=[]\n",
    "for i in rating_url[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        \n",
    "        ratings = driver.find_element(By.XPATH,\".//span[@class='a-icon-alt']/..\")\n",
    "        ratings = ratings.get_attribute('innerHTML').split(\">\")[1].split(\" \")[0]\n",
    "        rating.append(ratings)\n",
    "    except:\n",
    "        \n",
    "        \n",
    "        rating.append(\"00\")\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>RATING</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1,23,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad S540 11th Gen Intel Core i7 13....</td>\n",
       "      <td>4.3</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5,56,524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td>Previous</td>\n",
       "      <td>85,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion 13(2021) 11th Gen Intel Core i7 La...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>92,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33....</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1,07,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>98,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>73,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   TITLE    RATING     PRICE\n",
       "INDEX                                                                       \n",
       "1      HP Envy 11th Gen Core i7 Processor 13.3-inch (...       4.1  1,23,350\n",
       "2      Mi Notebook Horizon Edition 14 Intel Core i7-1...       4.2    57,990\n",
       "3      Lenovo IdeaPad S540 11th Gen Intel Core i7 13....       4.3    77,990\n",
       "4      ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...       3.7  5,56,524\n",
       "5      ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...  Previous    85,990\n",
       "6      ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...       3.0    84,990\n",
       "7      HP Pavilion 13(2021) 11th Gen Intel Core i7 La...       5.0    92,990\n",
       "8      Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33....       4.1  1,07,990\n",
       "9      Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...       4.1    98,500\n",
       "10     Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...       4.4    73,990"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating DataFrame for the scraped data\n",
    "import pandas as pd\n",
    "laptop_df=pd.DataFrame()\n",
    "laptop_df['INDEX']=range(1,11)\n",
    "laptop_df['TITLE']=title[:10]\n",
    "laptop_df['RATING']=rating[:10]\n",
    "laptop_df['PRICE']=price[:10]\n",
    "laptop_df.set_index('INDEX',inplace=True)\n",
    "laptop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END OF WORKSHEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
